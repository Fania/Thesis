% !TEX root = ../main.tex

\chapter{Interpretation}
\label{ch:interpretation}

\emph{Part of this research has been described in a journal article in Digital Creativity in 2013, and I presented a paper at the Creativity and Cognition conference 2013 in Sydney.}

\grule

\begin{draft}
  Creativity should be seen as a continuum, there is no clear cut-off point or Boolean answer to say precisely when a person or piece of software has become creative or not.
\end{draft}

Evaluating creative software is not an easy task. Pease and Colton [27] divide it into two notions: \\
•	whether an idea or artefact is valuable or not, and\\
•	whether a system is acting creatively or not.\\

We would need to investigate each individual search result in terms of its value and creativity. This could be done by user ratings or satisfaction questionnaires. Rather than measuring the success of individual results we could look at evaluation them as one set instead, similar to the blind side-by-side comparisons by Bing or MillionShort .

The search results produced by our tool can be quite surprising sometimes and it not always clear how they connect to the initial query (especially if the inner workings of the algorithms are unknown), even if we identify through which function a result has been obtained. Obviously these keywords might not be helpful to users unfamiliar with the concept of pataphysics and might therefore appear rather nonsensical. Whilst there is a clear logic to each search result, they might appear anomalous to the user’s expectations if he received these results without knowing the philosophy of the search tool. The results could possibly appear random then, and would therefore likely to be detrimental to the user.

To prevent that, the level of interaction the user has with the system and the feedback the system gives to the user on decisions it is making will have a large influence on the overall effectiveness and appreciation of the tool. A quick and simple solution to this problem would be to add an icon to the side of each search result, which displays exactly how the original query was pataphysicalised.


Creativity does not have a universally accepted definition. Creativity is a human quality and definitions don’t necessarily lend themselves to be applied to computers as well. There are aspects that come up in many, like novelty and value, but some that rarely pop up, like relevance and variety. Creativity can be studied at various \textbf{levels} (neurological, cognitive, and holistic/systemic), from different \textbf{perspectives} (subjective and objective) and \textbf{characteristics} (combinational, exploratory and transformative). Creativity should be seen as a continuum, there is no clear cut-off point or Boolean answer to say precisely when a person or piece of software has become creative or not.

Current evaluation methodologies have concentrated on only a handful of the points raised above, for example studying only the creative end-product itself (out of context), only judging it by its novelty objectively, assigning an arbitrary thresholds, etc. This also includes the assumption that machines "only" mimic humans and are therefore not judged by full potential.

\begin{comment}
  What does it mean, how can it be measured?

  Subjectivity vs objectivity is a theme throughout

  How is it defined and measured in humans, what can we just take directly from those concepts and apply them directly to machines and what needs to be completely redefined?
\end{comment}

This paper discusses issues related to the study of creativity in a computer science context. Two transdisciplinary fields of study have emerged from the variety of disciplines concerned. These are computational creativity and creative computing. The former lies at the cross section of artificial intelligence and cognitive science and the latter is mostly distinguished by its involvement in art. Creative computing focuses on the process of creativity rather than just the outcome as in computational creativity. In the remainder of this paper, CC will always denote creative computing unless otherwise specified.

\begin{comment}
  Many of these (if not all) spawn from the computational creativity discipline.

  Introduce the difference between human and computer evaluation/creativity?
\end{comment}

\begin{quote}
  "In research communities, approaches to the study of creativity differ in three main respects: 1) the type of research design, whether experimental, psychometric, observational etc. 2) the focus of the research, whether on human attributes cognitive processes or features of creative outcomes, and 3) the type of information that is used for the basis of evidence, by which is meant whether the time frame is present (real-time observation) or past (historical data) and whether the situation is artificial (laboratory) or natural (real world settings)." \citep[p.3]{Candy2012}
\end{quote}

\begin{comment}
  distinguishing between person’s and product’s creativity \citep[p.258]{Piffer2012}
  it is concluded that a person’s creativity can only be assessed indirectly (for example with self report questionnaires or official external recognition) but it cannot be measured \citep[p.258]{Piffer2012}
\end{comment}


\subsection{Measurable Attributes}

\begin{table}[htb]
  \begin{tabu}{XXXXXX}
  \toprule
  \textbf{Novelty}
  &
  \textbf{Value}
  &
  \textbf{Quality}
  &
  \textbf{Ephemeral Uncontrolled}
  &
  \textbf{Temporal Controlled}
  &
  \textbf{Purpose}
  \\ \midrule
  Originailty
  &
  Usefulness
  &
  Skill
  &
  Serendipity
  &
  Persistence
  &
  Intention
  \\ \midrule
  Newness
  &
  Appropriateness
  &
  Efficiency
  &
  Randomness
  &
  Results
  &
  Communication
  \\ \midrule
  Variety
  &
  Appreciation
  &
  Competence
  &
  Uncertainty
  &
  Development
  &
  Evaluation
  \\ \midrule
  Typicality
  &
  Relevance
  &
  Intellect
  &
  &
  Progression
  &
  Aim
  \\ \midrule
  Imagination
  &
  Impact
  &
  Acceptability
  &
  &
  Spontaneity
  &
  \\ \midrule
  &
  Influence
  &
  &
  Experimentation
  &
  &
  Independence
  \\
  \bottomrule
  \end{tabu}
\caption[Creativity attributes]{Summary of all creativity attributes}
\label{creatt}
\end{table}

\begin{comment}
  Temporal, spatial, ephemeral… what else?
\end{comment}

\begin{shaded}
  Summary\\
  •	Mimicking\\
  •	novelty + value + quality\\
  •	randomness + serendipity
\end{shaded}

\section{Problems with Evaluation}

Evaluating \textbf{human creativity} is problematic.

There are many debates across the involved disciplines. Specifically, Mayer identified five big questions of human creativity research: \citep[p.450-451]{Mayer1999}

\begin{enumerate}
  \item Is creativity a property of people, products, or processes?
  \item Is creativity a personal or social phenomenon?
  \item Is creativity common or rare?
  \item Is creativity domain-general or domain-specific?
  \item Is creativity quantitative or qualitative?
\end{enumerate}

\begin{quote}
  "An important challenge for the next 50 years of creativity research is to develop a clearer definition of creativity and to use a combination of research methodologies that will move the field from speculation to specification." \citep[p.459]{Mayer1999}
\end{quote}

Taking these debates about human creativity and directly applying them to machines seems logical but may be the wrong and lazy approach. Adapting Mayer’s five big questions to machines does not seem to capture the real issues at play.

\begin{enumerate}
  \item Is creativity a property of programmers, users, machines, products, or processes?
  \item Is creativity a local, a network or an Internet phenomenon?
  \item Is creativity common or rare? (P or H creativity)
  \item Is creativity domain-general or domain-specific?
  \item Is creativity quantitative or qualitative?
\end{enumerate}

\begin{comment}
  \begin{itemize}
  \item Can a machine judge whether a human is creative?
  \item Is creativity a property of machines (hardware or software?)
  \item Is mimicking human creativity really enough and appropriate?
  \item Compare against "human creativity"? Or define machine creativity from scratch?
  \item Who is creative? The programmer or the program?
  \item Can creativity be objectively measured?
  \item Quantitative or qualitative?
  \item In respect to P or H creativity?
  \item Output minus input? (we don’t have the same strict judgement on humans)
  \item Is it the product or the process or both?
  \item Does context matter? (Blind deaf dumb person = computer?)
  \item Does time matter?
  \item Does purpose or intention matter?
  \item AGI vs AI? Artificial general creativity vs artificial creativity?
  \end{itemize}
\end{comment}

On a more practical level, there are various problems that arise when trying to evaluate computer creativity. Anna Jordanous found that "evaluation of computational creativity is not being performed in a systematic or standard way" \citep[p.2]{Jordanous2011}(her emphasis).

\begin{comment}
(neurological, cognitive and systemic) in the computer sense!

Since most problems with evaluating creativity in computers (and humans alike) stems from the lack of a universal definition it seems logical to try and remedy this first and foremost.

Creativity is studied in many disciplines.
\begin{itemize}
  \item understanding the chemical mechanisms within the brain (neurological)
  \item understanding the thought processes associated with creativity (cognitive)
  \item understanding creativity in children and adults, novices and professionals
  \item understanding creativity in individuals and society (holistic)
\end{itemize}

Creativity is a continuum, which means that being creative and not being creative form the two distinct extreme ends of a scale.

\begin{quote}
  "a continuous sequence in which adjacent elements are not perceptibly different from each other, but the extremes are quite distinct" [OED]
\end{quote}

(subjective and objective)

How can we model Koestler’s bisociative creativity in computers?
Boden/Kaufman: Subjective and objective types (pandh or little-candbig-C) \citep{Boden2003, Kaufman2009} (product+process)

DIGITAL CREATIVITY ?!?!?! Mix between digital humanities and creative computing/computational creativity ---- see Digital Creativity Journal!!!!
Unified theory of creativity! (Koestler?)
Unified definition!

\begin{enumerate}
  \item What is the definition of creativity?
  \item Who is being creative? WHO
  \item What was the aim/intention, if any?
  \item What was the process, approach? HOW
  \item What factors influenced the person/process? WHERE
  \item What is the result/product, if any? Is it original, relevant? WHAT
  \item What is the impact, if any?
  \item What is the maintenance plan, if any?
\end{enumerate}
\end{comment}


\section{5 P’s: product, process, people, place and purpose}

\begin{quote}
  One way of characterizing these processes is to use an alliteration that allows us to keep track of some of the core features of RRI in ICT, namely the four P's, which are: product, process, purpose and people. The purpose of using the four P's is to draw attention to the fact that, in addition to the widely recog- nized importance of both product and process of technical development, the purpose of the development needs to be considered and people involved in the innovation need to be incorporated in RRI. \citep[p.203, my emphasis]{Stahl2013}
\end{quote}

\begin{comment}
  combine the 4 P’s with purpose//
  5 P’s: product, process, people, place and purpose//
  Why is the purpose important?//
  Interpreting or Measuring?//
  Maybe we should not be looking for metrics but rather guidelines for interpretations of creativity.
\end{comment}

\begin{draft}
  In the end I believe it is impossible to measure creativity objectively. I don’t just think it is impossible, I think it is unwise to try and do so. It would be silly to put a percentage on how creative something is just like it would be silly to say a certain product is 50percent ethical. In fact there are lots of parallels between (computer) ethics and (computer) creativity. Both are subjective, both are highly dependent on context.

  What is important is to study and consider the factors that influence our perception of whether something is creative (or ethical) and what the implications are.

  Creativity in a process or product will mean different things to different people, in different environments and contexts.
  Common sense.

  Just as there are people who just cannot see any creativity in in modern art, there will always be people who wont accept anything produced by a computer as creative.
\end{draft}


% -----------------------------

% \begin{comment}
% •	Brain operations per sec 1016 \citep[p.194]{Kurzweil2013}\\
% •	Japan’s K-computer has 1016 calculations per sec (10 petaflops)\\
% •	Blue brain project: 2023: 1017 bytes memory + 1018 flops \citep[p.125]{Kurzweil2013}
% \end{comment}
%
% Human Brain Project: \citep{Walker2012}
%
% Our brain consumes about 30W, the same as an electric light bulb, thousands of times less than a small supercomputer. \citep[p.17]{Walker2012}
%
% For environmental and business reasons, vendors have set themselves the goal of containing energy consumption to a maximum of 20 megawatts  \citep[p.41]{Walker2012}
%
% the 1 PFlop machine at the Jülich Supercomputing Centre could simulate up to 100 million neurons – roughly the number found in the mouse brain. \citep[p.41]{Walker2012}
%
% Cellular-level simulation of the 100 billion neurons of the human brain will require compute power at the exascale (1018 flops). \citep[p.41-42]{Walker2012}
%
% 2017 petascale 50petabytes memory + 50 petaflops + <=4MW power
%
% 2021 exascale 200petabyte memory + 1exaflop
%
% A second, equally important goal will be to prepare the procurement of the HBP Pre-exascale-supercomputer. By 2017/18, Jülich plans to procure a Big Data-centred system with at least 50 PBytes of hierarchical storage-class memory, a peak capability of at least 50 PFlop/s and a power consumption <= 4 MW. The memory and computational speed of the machine will be sufficient to simulate a realistic mouse brain and to develop first-draft models of the human brain. (The rest of the hardware roadmap targets an exascale machine in 2021/2022 with a capability of 1 EFlop/s and a hierarchical storage-class memory of 200 PB).\footnote{https://www.humanbrainproject.eu/high-performance-computing-platform}
%
% Chris Chatham: 10 Important Differences Between Brains and Computers \footnote{http://scienceblogs.com/developingintelligence/2007/03/27/why-the-brain-is-not-like-a-co/}
%
% \begin{enumerate}
% \item Brains are analogue; computers are digital
% \item The brain uses content-addressable memory
% \item The brain is a massively parallel machine computers are modular and serial
% \item Processing speed is not fixed in the brain; there is no system clock
% \item Short-term memory is not like RAM
% \item No hardware/software distinction can be made with respect to the brain or mind
% \item Synapses are far more complex than electrical logic gates
% \item Unlike computers, processing and memory are performed by the same components in the brain
% \item The brain is a self-organising system
% \item Brains have bodies
% \item	The brain is much, much bigger than any [current] computer
% \end{enumerate}
%
% Why Minds Are Not Like Computers \citep{Schulman2009}
% Software – Hardware == Mind – Brain ??? analogy
%
% "The power of the computer derives not from its ability to perform complex operations, but from its ability to perform many simple operations very quickly."
%
% Layers of abstraction in computers:\\
% 1.	user interface\\
% 2.	high level programming language\\
% 3.	machine language\\
% 4.	proessor microarchitecture\\
% 5.	Boolean logic gates\\
% 6.	transistors\\
%
% layers of abstraction in brain:\\
% 1.	personality?\\
% 2.	Thinking?\\
% 3.	Chemical /electrical signals/activity?\\
% 4.	Divided Brain regions/structure\\
% 5.	Neurons\\
% 6.	Dendrites (input) and axons (output)?\\
%
%
% Computers are faster and better than humans in many tasks already.
%
% \begin{quote}
% "The weaknesses of the computational approach include its assumption that cognition can be reduced to mathematics and the difficulty of including noncognitive factors in creativity." \citep[p.457]{Mayer1999}
% \end{quote}
%
% \subsection{Other}
%
% \begin{quote}
% "Currently many implementors of creative systems follow a creative-practitioner-type approach: produce a system then present it to others, whose critical reaction determines its worth as a creative entity. A creative practitioner’s primary aim, however, is to produce creative work, rather than to critically investigate creativity; in general this investigative aim is important in computational creativity research." \citep{Jordanous2011}
% \end{quote}
%
% purpose or intention shifts into focus here over production of products.
%
% \begin{quote}
% "Also, evaluation of novelty (or originality, newness) is often examined in the papers cited above according to how dissimilar the system’s artefacts are to previous output or other existing examples of creative output in that domain. On the other hand, appropriateness is often evaluated according to how similar the system’s output artefacts are to known examples. Hence across the field as a whole, there is a stark inconsistency as to whether to prioritise the generation of artefacts which are dissimilar from existing artefacts, or whether to pursue the generation of artefacts which are similar to existing artefacts, arising directly from the adoption of ‘novelty + value’ as the underlying model of creativity. Such a contradiction is clearly not helping the identification of coherent and consistent strategies to adopt across the field." \citep{Jordanous2012}
% \end{quote}
%
% \begin{quote}
% "In some cases, evaluative tests are conducted on the system which purportedly evaluate the system’s creativity but which actually only measure the system’s quality." \citep{Jordanous2012}
% \end{quote}
%
% But if quality is the "conformance to specifications" and the specification suggested creativity, then a good quality rating of a system would automatically mean it's creative, right?
%
% \begin{quote}
% "The key conclusion of the survey was that evaluation of computational creativity is not being performed in a scientifically rigorous manner:
% \begin{itemize}
% \item The creativity of a third of the 75 ‘creative’ systems was not critically discussed.
% \item Half the papers surveyed did not contain a section on evaluation.
% \item Only a third of systems presented as creative were actually evaluated on how creative they are.
% \item A third of papers did not clearly state or define criteria that their system should be evaluated by.
% \item Less than a quarter of systems applied existing creativity evaluation methodologies.
% \item Occurrences of evaluation by people outside the system implementation team were rare.
% \item Few systems were comparatively evaluated, to see if the presented system outperforms existing systems (a useful measurement of research progress).
% \item General principles of scientific method are not being followed by the community as a whole." \citep{Jordanous2012}
% \end{itemize}
% \end{quote}
%
% \begin{quote}
% "Reducing creativity to problem solving works when the creator is searching for an ideal solution which is not obvious, or if there is no single ideal solution but several candidates for a reasonable solution (Boden, 1994b)." \citep{Jordanous2012}
% \end{quote}
%
% \begin{quote}
% "One potential problem with Boden’s three views of creativity is that they all assume the existence of a conceptual space, or constrained set of possibilities, that the creative individual consciously reasons with in order to be creative." \citep{Jordanous2012}
% \end{quote}
