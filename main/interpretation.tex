% !TEX root = ../main.tex

\chapter{Interpretation}
\label{ch:interpretation}

\startcontents[chapters]

\vfill

\begin{alltt}\sffamily
My explanation however satisfied him,
mistaking them for land,
for understanding the syntax and construction of old boots,
furnisheth the Fancy wherewith to make a representation.

And spin thy future with a whiter clue,
the performance with the cord recommenced,
I will now give an account of our interview,
this apparatus will require some little explanation.

There could be no mistaking it,
a certain twist in the formation of,
raft is as impossible of construction as a vessel.

Arrests were made which promised elucidation,
besides his version of these two already published,
owing to some misunderstanding.
\end{alltt}

\newpage
\minicontents
\spirals

% \emph{Elements of this chapter were published in \autocite{Raczinski2016}\marginpar{§~\ref{app:pub}}.}

% \spirals

\begin{quotation}
  Interpretation is rethought through the encounter with computational methods and [\ldots] computational methods are rethought through the encounter with humanistic modes of knowing. \sourceatright{\autocite{Burdick2012}}
\end{quotation}

Using algorithms to generate creative work is a well-established transdisciplinary practice that spans several fields. Accessible and popular coding tools such as Processing\footnote{Processing is a Java-based ``flexible software sketchbook and a language for learning how to code within the context of the visual arts'' \autocite{Frynd}.} and openFrameworks\footnote{openFrameworks is ``an open source C++ toolkit designed to assist the creative process by providing a simple and intuitive framework for experimentation'' \autocite{Liebermannd}.}, as well as the rise of so-called `hack spaces' have significantly contributed to increased activity in this field. However, beyond art-technology curation and historical contextualisation, evaluation of the resulting artefacts is in its infancy, although several general models of creativity---and its evaluation---exist.

There is a perceived distinction between human and computer creativity, whereas they are effectively the same thing. Computers are made and programmed by people, so it makes sense to measure the creativity of the human influence behind the machine, rather than viewing computers as truly autonomous entities.

\acf{AMC} is neither machine creativity nor human crea\-tivity---it is both. By acknowledging the undeniable link between computer creativity and its human influence (the machine is just a tool for the human) we enter a new realm of thought. By concatenating and enhancing existing models of creativity and its assessment, this chapter proposes a framework for the evaluation and interpretation of \ac{AMC}.

\spirals

Although using computers to generate creative work has its roots in the 1950s \autocite{Candy2011, Copeland2016}, John Maeda's Design By Numbers \autocite*{Maeda2001} and from around 2010 a slew of similar initiatives followed Processing's lead. However, due in part to the niche position of artists working with technology, and also because such activity was overlooked or ignored until relatively recently by arts bodies and critics, formal evaluation of the creativity in such work lagged behind.

In this context humans simply use computers as tools for their creativity---no matter how autonomous the machine output may appear, or how far it travels from the original intentions of the programmer, its origins nevertheless reside in the humanly-authored code that produces the output.

This is overlooked in anthropomorphic approaches that regard computers as being capable of creativity in their own right. Computer output cannot be conceptually separated from the craft/skill/intention of the programmer, even when the results are unexpected or accidental. The illusion of creativity can be produced by introducing randomness, serendipity, etc. but this is not the same as the intuitive decision-making that drives human creativity.

Hypothetical `zombies' (popularised by philosopher David Chalmers \autocite*{Chalmers1996}) are entities that appear identical to humans in every way but lack conscious experience. Throughout the following chapters, this term is borrowed and applied to computers which appear creative but lack real autonomous intent.


\section{Problems}

Creativity and the subjective properties associated with it, lack a universally accepted definition as I have shown in chapter~\ref{ch:creativity}\marginpar{§~\ref{ch:creativity}}. 

Perhaps the problem starts in the etymology of the word `creativity'. Still and d'Inverno discuss the two roots of the word: ``one originating in the classical Latin use of the word `creare' as a natural process of bringing about change, the other in Jerome's later use in the Vulgate bible, referring to the Christian God's creation of the world from nothing but ideas.''\autocite*{Still2016}.

As a human quality it has definitions that don't necessarily lend themselves to be applied to computers. However, there are several important theories and evaluation frameworks concerning human and computer creativity\marginpar{§~\ref{ch:evaluation}}, and these are the basis for this chapter. Some aspects, like `novelty' and `value', recur in many models of creativity but some, like `relevance' and `variety', rarely appear; while other terms are problematic when it comes to computing. 

Computer systems are generally evaluated\marginpar{§~\ref{s:evalsearch}} against functional requirements and performance specifications, but creativity should be seen as a continuum, as there is no clear cut-off point or Boolean answer to say precisely when a person or piece of software has become creative or not.

\begin{quotation}
  The expression of our language systems in computer code confers no semantic understanding autonomously on the computer system. The computer system only acts as a tool for transferring symbols and communicating meaning between humans. \sourceatright{\autocite{Mcbride2012}}
\end{quotation}

True \ac{AI} and true artificial creativity are equally elusive. For a computer to become truly intelligent and creative, it would need to break out of the programming procedures by which it operates. Yet it is bound to follow rules, no matter how emergent the outcome. The paradox is that it needs to recognise its constraints in order to break free from them. Yet, programmatically defining yet more rules to allow that to happen---even when those rules enable machine learning---is tautological (and pataphysical)!

\spirals

Some of the key ideas introduced in the \nameref{ch:evaluation} chapter\marginpar{§~\ref{ch:evaluation}} are listed here as a reminder:

\begin{itemize}
  \item Output minus input (ignoring the inspiring set/training data)
  \item Creative Tripod (mimicking skill, appreciation, and imagination)
  \item Measurement of specific criteria (novelty, usefulness, quality)
  \item Measuring product, process or both
  \item Ontology of Creativity (14 key components)
  \item \ac{SPECS} (define creativity, define standards, test standards against definition)
  \item \ac{MMCE} (people, process, product, context)
  \item \ac{CSF} (formal notation based on Boden)
\end{itemize}


\subsection{Anthropomorphism}
\label{ss:anthropomorphism}

\begin{quotation}
  The uncodifiable must be reduced to the codable in the robot. In reducing a complex moral decision (tacit, intuitive, deriving knowledge from maturity) to the execution of a set of coded instructions, we are throwing away vast stretches of knowledge, socialisation and learning not only built up in the individual, but also in the community and the history of that community, and replacing it with some na{\"i}ve ``yes'' or ``no'' decisions. \sourceatright{\autocite{Mcbride2012}}
\end{quotation}

McBride's observation is echoed by Indurkhya, who argues that because computers don't make decisions based on personal or cultural concepts (even when these are included in code), they are more likely to make connections that humans will perceive as `creative leaps' \autocite*{Indurkhya1997}. These leaps \emph{appear} creative only because we are anthropomorphising not only the output, but in some cases even the \emph{intent} behind it, as if this originated in the computer itself rather than as an output from algorithmic processes. This phenomenon is most apparent in the `uncanny valley' created by those areas of robotics that seek to create human companions, or where the intent is to imbue the computer with a personality. This is even the case for simple web interfaces, let alone computers that might mimic human creativity:

\begin{quotation}
  Automatic, mindless anthropomorphism is likely to be activated when anthropomorphic cues are present on the interface. [\ldots] it is noteworthy that anthropomorphic cues do not have to be fancy in order to elicit human-like attributions. \sourceatright{\autocite{Kim2012}}
\end{quotation}

The phenomenon of ascribing human qualities to non-human artefacts and machines depends on the prior associations (concept networks) humans have with certain activities, including creativity. It leads to metaphorical statements such as ``this interface is friendly'', ``a bug snuck into my code'' or ``the computer is being creative'', and appears in media article headlines such as `Patrick Tresset\rq s robots draw faces and doodle when bored' \autocite{Wired2011}, as if there were conscious intent behind the code generating such activity in Tresset's sketching bot \textit{Paul}.

Perhaps one of the earliest pieces of evidence for computer anthropomorphisation stems from the Copeland-Long restoration of some computer music, recorded at Alan Turing's laboratory in Manchester in 1951 \autocite{Copeland2016}. In the recording, a female voice is heard saying phrases like: ``he resented it'', ``he is not enjoying this'' and ``the machine's obviously not in the mood'' (creating a pun---as the machine is trying to play Glen Miller's `In the mood') referring to the computer in an anthropomorphic `he'.


\subsection{The Programmer}
\label{s:programmer}

This tendency of anthropomorphising computers has implications for the aimed-for objectivity when evaluating certain creative computing projects, one of the most well-established being Harold Cohen's \textit{AARON}, artist-authored software that produces an endless output of images in his own unique style. While documenting the process of coding his system, Cohen asked:

\begin{quotation}
  How far could I justify the claim that my computer program---or any other computer program---is, in fact, creative? I'd try to address those questions if I knew what the word ``creative'' meant: or if I thought I knew what anyone else meant by it. [\ldots] ``Creative'' is a word I do my very best never to use if it can be avoided. [\ldots] AARON is an entity, not a person; and its unmistakable artistic style is a product of its entitality, if I may coin a term, not its personality. \sourceatright{\autocite{Cohen1999}}
\end{quotation}

He goes on to outline four elements of \emph{behaviour X} (his placeholder for creativity): (1) `emergence' produced from the complexity of a computer program, (2) `awareness' of what has emerged, (3) `willingness' to act upon the implications of what has emerged, and (4) `knowledge' of the kind manifest in expert systems. He identifies three of these properties as programmable (within limits), but ``as to the second element, the program\rq s awareness of properties that emerge, unbidden and unanticipated, from its actions\ldots  well, that\rq s a problem.'', and concludes that ``it may be true that the program can be written to act upon anything the programmer wants, but surely that\rq s not the same as the individual human acting upon what he wants himself. Isn\rq t free will of the essence when we\rq re talking about the appearance of behaviour X in people?'' \autocite{Cohen1999}. In other words, a decision tree in computing is not the same as a human decision-making process. As for whether his life's work is autonomously creative:

\begin{quotation}
  I don't regard AARON as being creative; and I won't, until I see the program doing things it couldn't have done as a direct result of what I had put into it. That isn't currently possible, and I am unable to offer myself any assurances that it will be possible in the future. On the other hand I don't think I've said anything to indicate definitively that it isn't possible. \sourceatright{\autocite{Cohen1999}}
\end{quotation}

In the same manner as in the field of computer ethics, i.e. ``the ethics of the robot must be the ethics of the maker'' \autocite{Mcbride2012}, the creative computer must ultimately be a product of the creativity of the programmer. To hijack Barthes' conclusion in \textit{The Death of the Author}: \emph{the birth of the truly creative computer must be ransomed by the death of the programmer} \autocite[adapted from][]{Barthes1967}---in other words, a truly creative computer must be able to act without human input, yet any computer process presumes a significant amount of human input in order to produce such so-called autonomous behaviour, so the question is whether that behaviour can ever be regarded as truly autonomous or creative---no matter how independent it appears to be.

Initiatives like the Human Brain project suggest that we are far from the capacity to reproduce the level of operations necessary to even mimic a human brain ``the 1 PFlop machine at the J{\"u}lich Supercomputing Centre could simulate up to 100 million neurons---roughly the number found in the mouse brain.'' \autocite{Walker2012}. And even if it were possible today to scale this up to the human brain, the end-result might still turn out to be a \emph{zombie}. See chapter~\ref{s:braincomp}\marginpar{§~\ref{s:braincomp}}.

\spirals

Interestingly, Mumford and Ventura argue that the idea that a ``computer program can only perform tasks which the programmer knows how to perform'' is a common misconception among non-specialists which ``leads to a belief that if an artificial system exhibits creative behavior, it only does so because it is leveraging the programmer's creativity'' \autocite*{Mumford2015}.

\begin{quotation}
  Because computers are currently perceived as incapable of autonomy and thought, as programmers, we will be credited for and be held accountable for what our programs do. \sourceatright{\autocite{Mumford2015}}
\end{quotation}

They question whether it is possible to ``possess all of the creative attributes typically outlined in our field (appreciation, skill, novelty, typicality, intentionality, learning, individual style, curiosity, accountability), and yet still not be creative'' and also whether a machine can ``be creative without being intelligent'' \autocite{Mumford2015}.

\begin{quotation}
  Is general or strong artificial intelligence necessary before people become comfortable with ascribing creativity to a machine? \sourceatright{\autocite{Mumford2015}}
\end{quotation}

Oliver Bown adds to Mumford and Ventura's point above, stating that ``it is common to make the simplifying assumption that the most direct contributor to an artefact is that artefact's sole author'', i.e. that the programmer is the only creative agent and does not include the program in itself as a contributor \autocite*{Bown2015}.

However, of course, he adds that ``all human creativity occurs in the context of networks of mutual influence, including a cumulative pool of knowledge'' \autocite{Bown2015}. Bown goes on to propose a better formalisation of `creative authorship' ``such that for any artefact, a set of agents could be precisely attributed with their relative contributions to the existence of that entity'' \autocite*{Bown2015}.


\subsection{Mimicry}
\label{s:mimicry}

Current evaluation methodologies in creative computing disciplines have concentrated on only a handful of the facets raised in the \nameref{ch:evaluation}\marginpar{§~\ref{ch:evaluation}} chapter, for example studying only the creative end-product itself (out of context), only judging it by its objective novelty, assigning an arbitrary thresholds, etc. This also includes the assumption that machines `mimic' humans and are therefore not judged at their full potential. For example we generally do not take into account the differences between humans and machines or, more precisely, the differences between the human brain and computer processors\marginpar{§~\ref{s:braincomp}}. In fact, it could be said that we are in danger of limiting computers in their vast potential so that they \emph{appear} more human.

True \ac{AI} and artificial creativity are equally elusive. Just as the Turing Test \autocite{Turing1950} is flawed (because it is designed to fool humans into thinking a machine is a person, but only through mimicry), the view that something \emph{is} creative because it \emph{appears} creative is similarly flawed. This is the premise behind by Searle's `Chinese room' argument\marginpar{§~\ref{s:undersimu}} \autocite*{Searle1980} where an individual with a map of English to Chinese symbols can appear to someone outside the room to `know' Chinese. By inference, just because a computer program appears to produce a creative output, this doesn't mean that it is inherently creative---it just follows the rules that produce output from a human creation in an automated manner. To take this further, we could even state that machines programmed to mimic human creativity and produce artefacts that appear creative are---in the philosophical manner defined by Chalmers---\emph{zombies} \autocite*{Chalmers1996}. Similarly Douglas Hofstadter argues that minds cannot be reduced to their physical building blocks (or their most basic rules) in his \textit{Conversation with Einstein's Brain} \autocite*{Hofstadter1981}. This school of thought is employed to demonstrate that \emph{mind} is not just physical \emph{brain}\marginpar{§~\ref{s:braincomp}}. It is introduced here to argue that computers do not \emph{consciously create} as do humans, because they are not conscious.


\subsection{Infantalisation}
\label{s:babying}

Creativity is a transdisciplinary activity and is apparent in many diverse fields, yet it is often studied from within a single discipline within which other perspectives and theories can be overlooked. Therefore, creative evaluation is subjective, and involves an emotional component related to the satisfaction of a set of judgments. These judgments are mutable when subjected to personal, social and cultural influence, so we can only try to evaluate a creative activity objectively via approximations.

Dijkstra pointed out that computer science is infantalised \autocite*{Dijkstra1988}\footnote{Interestingly he anthropomorphises computer science here---which he criticises strongly in the same article.} and there is a danger that the same thing is happening to creativity research. In other words, it may be an over-simplification to reduce creativity down to a four step process, or a product that is novel, valuable and of high quality. A framework that makes the evaluation of creativity appear to be a matter of checking boxes is surely missing the subjective nature of creativity. The real picture is far more interwoven and---although creativity may spring from a finite set of causes---these can interact in a complex manner that cannot be assessed so neatly.

Creativity is a complex human phenomenon that is:

\begin{itemize}
  \item not just thinking outside the box
  \item not just divergent thinking
  \item not just about innovation, usefulness or quality
  \item not just a `Eureka' moment
  \item not just a brainstorming technique
  \item not just for geniuses
  \item not just studied in psychology
\end{itemize}

This is also apparent in various studies that evaluate only one single aspect of creativity as a measure of overall creativity. Examples are summarising creativity as `unexpectedness' \autocite{Kazjon2014} or `surprise' \autocite{Maher2013}.

% \subsection{Abstraction}

% see formal maths equations which are very hard to apply in real life eg wiggins cfs, bayensian surprise, precision recall...


% \subsection{Incompleteness}

% \autocite{Varshney2013}
% novelty = Bayesian surprise \autocite{Baldi2010}
% which is:

% \begin{quotation}
%   Computational creativity applies technology to assist humans in thinking outside the box and expanding their exploration boundaries. \sourceatright{\autocite{Varshney2013}\footnote{\url{http://research.ibm.com/cognitive-computing/computational-creativity.shtml}}}
% \end{quotation}

% \begin{equation}
%   \begin{split}
%     \textrm{Bayesian surprise} = D(p(M|A) \ \parallel  \ p(M))\\
%     &= \int_{\mathcal{M}}p(M|A) \ log \ \frac{p(M|A)}{p(M)} \ dM
%   \end{split}
%   \label{eq:bsurprise}
% \end{equation}
% % \myequations{Bayesian surprise}
%
% Where:
% \itab{$\mathcal{M}$} \tab{is the set of artefacts known to the observer,}\\
% \itab{$M$} \tab{an artefact, with $M \in \mathcal{M}$,}
% \itab{$A$} \tab{a new artefact,}
% \itab{$p(M)$} \tab{the probability of an existing artefact,}
% \itab{$p(A|M)$} \tab{the conditional probability of the new artefact given the existing artefacts $M$,}
% \itab{$p(M|A)$} \tab{the conditional probability of the existing artifacts given the new artifact $A$.}

% \colorbox{red!30}{our}


\subsection{Undefinitions}

Jordanous found that ``evaluation of computational creativity is not being performed in a systematic or standard way'' \autocite*{Jordanous2011}, which further confuses the problem of objective evaluation. To remedy this she proposed `\acf{SPECS}'\marginpar{§~\ref{s:specs}} (see chapter~\ref{ch:evaluation} for more details) \autocite*{Jordanous2012a}:

\begin{quote}
  \begin{enumerate}
    \item Identify a definition of creativity that your system should satisfy to be considered creative.
    \item Using Step 1, clearly state what standards you use to evaluate the creativity of your system.
    \item Test your creative system against the standards stated in Step 2 and report the results.
  \end{enumerate}
\end{quote}

The \ac{SPECS} model essentially means that we cannot evaluate a creative computer system objectively, unless steps 1 and 2 are predefined and publically available for external assessors to execute step 3. Creative evaluation can therefore be seen as a move from subjectivity to objectivity, i.e. defining subjective criteria for objectively evaluating a product in terms of the initial criteria.

\begin{quotation}
  For transparent and repeatable evaluative practice, it is necessary to state clearly what standards are used for evaluation, both for appropriate evaluation of a single system and for comparison of multiple systems using common criteria. \sourceatright{\autocite{Jordanous2012a}}
\end{quotation}

We need a ``clearer definition of creativity'' \autocite{Mayer1999}, with ``criteria and measures [for evaluation] that are situated and domain specific'' \autocite{Candy2012}.

\begin{quotation}
  [A] person's creativity can only be assessed indirectly (for example with self report questionnaires or official external recognition) but it cannot be measured. \sourceatright{\autocite{Piffer2012}}
\end{quotation}

Since many problems with evaluating creativity in computers (and humans alike) seem to stem from a lack of a clear relevant definition it seems logical to try and remedy this first and foremost.


\section{Creative Interpretation}
\label{s:creatint}

All of the theories of creativity\marginpar{§~\ref{ch:creativity}} and its evaluation mentioned above have value, but each alone\marginpar{§~\ref{ch:evaluation}} may be incomplete or contain overlaps. There is a misconception that creativity can be measured objectively and quantifiably, but given the issues discussed above, it is unlikely that any system will yield truly accurate measurements in practice, even if such accuracy were possible. As Schmidhuber suggests---``any objective theory of what is good art must take the subjective observer as a parameter'' \autocite*{Schmidhuber2006}---evaluation of creativity always happens from a subjective standpoint, originating in either the individual, or in the enveloping culture of which they are part.

This thesis therefore proposes two facets of a new approach that aims to obtain a more honest measure of the subjective judgments implied when evaluating creativity:

\begin{enumerate}
  \item a set of scales that can be used to approximate a `rating' for the creative value of an artefact,\marginpar{§~\ref{s:sec}}
  \item a set of criteria to be considered using the scales above,\marginpar{§~\ref{s:oec}}
  \item a combined framework for evaluation.\marginpar{§~\ref{s:framework}}
\end{enumerate}


\subsection{Subjective Evaluation Criteria}
\label{s:sec}

Following Jordanous' \ac{SPECS} model\marginpar{§~\ref{s:specs}}, we need to state our own definition of creativity in regards to the computer system being evaluated. An overview of recurring keywords in existing approaches suggests the following distillation of seven groups:

\begin{description}
  \item [Novelty] originality, newness, variety, typicality, imagination, archetype, surprise
  \item [Value] usefulness, appropriateness, appreciation, relevance, impact, influence
  \item [Quality] skill, efficiency, competence, intellect, acceptability, complexity
  \item [Purpose] intention, communication, evaluation, aim, independence
  \item [Spatial] context, environment, press
  \item [Temporal] persistence, results, development, progression, spontaneity
  \item [Ephemeral] serendipity, randomness, uncertainty, experimentation, emotional response
\end{description}

From these, I have derived the following \hypertarget{creadef}{\emph{creativity criteria}} --- \num{3} key criteria of creativity in relation to \num{4} major factors --- novelty, value, quality and purpose $\to$ spatial, temporal and ephemeral. Table~\ref{tab:subcreat}\marginpar{\faicon{table}~\ref{tab:subcreat}} shows each of the seven criteria with example indicators of the two extreme ends of each scale.

\begin{table}[!htbp]
\caption[Subjective scales for creativity]{Subjective scales for creativity}
\label{tab:subcreat}
\centering
  \begin{tabu}{cc}
  \toprule
  \textbf{Keyword} & \textbf{Scale} \\
  \midrule
  Novelty & Established $\leftrightarrow$ Novel \\
  Value & Playful $\leftrightarrow$ Purposive \\
  Quality & Minimal $\leftrightarrow$ Complex \\
  Purpose & Emotive $\leftrightarrow$ Thoughtful \\
  Spatial & Universal $\leftrightarrow$ Specific \\
  Temporal & Instant $\leftrightarrow$ Persistent \\
  Ephemeral & Accidental $\leftrightarrow$ Experimental \\
  \bottomrule
  \end{tabu}
\end{table}


\subsection{Objective Evaluation Constraints}
\label{s:oec}

In reference to the many kinds of `4 P' models\marginpar{§~\ref{ch:creativity}} of creativity and the `four P\rq s' of Stahl's computer ethics framework, I propose a set of evaluation constraints called the `5 P Model' --- product, process, people, place and purpose.

\begin{quotation}
  One way of characterizing these processes is to use [\ldots] the four P's, which are: product, process, purpose and people. The purpose of using the four P's is to draw attention to the fact that, in addition to the widely recognized importance of both product and process of technical development, the purpose of the development needs to be considered and people involved in the innovation [\ldots]. \sourceatright{\autocite{Stahl2013}}
\end{quotation}

The `5 P\rq s'---\textbf{Product, Process, Purpose, Person, Place}---are all components of any creative artefact (see table~\ref{tab:objcreat}\marginpar{\faicon{table}~\ref{tab:objcreat}}). They are nested in a similar fashion to figure~\ref{fig:4Crea}\marginpar{\faicon{object-group}~\ref{fig:4Crea}}.

\begin{figure}[!htbp] % (here, top, bottom, page)
  \centering
  \begin{tikzpicture}
    \node [draw, rectangle] (prod) {Product};
    \node [below= 0.2cm of prod] (proc) {Process};
    \node [below= 0.2cm of proc] (purp) {Purpose};
    \node [below= 0.2cm of purp] (pers) {Person};
    \node [below= 0.2cm of pers] (plac) {Place};
    \draw (-1,-1.15) rectangle (1,0.5);
    \draw (-1.2,-1.85) rectangle (1.2,0.7);
    \draw (-1.4,-2.65) rectangle (1.4,0.9);
    \draw (-1.6,-3.4) rectangle (1.6,1.1);  
  \end{tikzpicture}
\caption[5 P model]{5 P model}
\label{fig:5PModel}
\end{figure}

\begin{table}[!htbp]
\caption[Objective criteria of creativity]{Objective criteria of creativity}
\label{tab:objcreat}
  \centering
  \begin{tabu}{ll}
  \toprule
  \textbf{Criteria} & \textbf{Note} \\
  \midrule
  Product & Algorithmic sketch, poetry, audio, interactive installation\\
  Process & Procedural, Experimental, Heuristic, Systems-based\\
  Purpose & Accidental, Conceptual, Interactive, Time-based\\
  Person & Skill, Aesthetic values, Influences, Collaborations\\
  Place & Culture, Social environment, Education, Peers\\
  \bottomrule
  \end{tabu}
\end{table}


% \begin{draft}
%   In the end I believe it is impossible to measure creativity objectively. I don’t just think it is impossible, I think it is unwise to try and do so. It would be silly to put a percentage on how creative something is just like it would be silly to say a certain product is 50percent ethical. In fact there are lots of parallels between (computer) ethics and (computer) creativity. Both are subjective, both are highly dependent on context.
%
%   What is important is to study and consider the factors that influence our perception of whether something is creative (or ethical) and what the implications are.
%
%   Creativity in a process or product will mean different things to different people, in different environments and contexts.
%   Common sense.
%
%   Just as there are people who just cannot see any creativity in in modern art, there will always be people who wont accept anything produced by a computer as creative.
% \end{draft}% chktex 17


\subsection{Combined Framework}
\label{s:framework}

The \textbf{constraints} listed in table~\ref{tab:objcreat} should be considered objectively, while the \textbf{criteria} in table~\ref{tab:subcreat} are judged subjectively. The set of scales is directly derived from the various frameworks for evaluating creativity reviewed in the previous sections\marginpar{§~\ref{ch:evaluation}}.

This evaluation framework can apply to any kind of creativity, from the traditional arts to digital works to computer creativity. Because the scale element allows for the measurement of subjective qualities, it circumvents binary yes/no or check-box approaches and therefore makes it possible to gather quantitative values from the subjective judgments involved in evaluating creativity in general.

The terms on each end of the scales (as shown in table~\ref{tab:subcreat}\marginpar{\faicon{table}~\ref{tab:subcreat}}) are suggestions only and should not be taken as value judgments. Rather, they should be adapted for each project individually. Numeric values can be assigned to the scales if needed according to specific evaluative requirements.

% \begin{figure}[!htbp]
%   \centering
%   \includegraphics[width=\linewidth]{evalmatrix}
%   \caption[Evaluation Matrix]{Creative Evaluation Matrix}
% \label{evalmatrix}
% \end{figure}

\begin{figure}[!htbp] % (here, top, bottom, page)
  \centering
  \begin{tikzpicture}
  \draw[help lines] (0,0) grid (7,5);
  \node [anchor=east] at (-0.2,4.5) {Place};
  \node [anchor=east] at (-0.2,3.5) {Person};
  \node [anchor=east] at (-0.2,2.5) {Purpose};
  \node [anchor=east] at (-0.2,1.5) {Process};
  \node [anchor=east] at (-0.2,0.5) {Product};
  \node [rotate=90, anchor=west] at (0.5,5.2) {Novelty};
  \node [rotate=90, anchor=west] at (1.5,5.2) {Quality};
  \node [rotate=90, anchor=west] at (2.5,5.2) {Value};
  \node [rotate=90, anchor=west] at (3.5,5.2) {Purpose};
  \node [rotate=90, anchor=west] at (4.5,5.2) {Spatial};
  \node [rotate=90, anchor=west] at (5.5,5.2) {Temporal};
  \node [rotate=90, anchor=west] at (6.5,5.2) {Ephemeral};
  \end{tikzpicture}
\caption[Interpretation and evaluation matrix]{Interpretation and evaluation matrix}
\label{fig:matrix}
\end{figure}

Figure~\ref{fig:matrix} shows a blank matrix to be filled by judges. The rows and columns correspond to the objective constraints discussed in section~\ref{s:oec}\marginpar{§~\ref{s:oec}} and the subjective criteria from section~\ref{s:sec}\marginpar{§~\ref{s:sec}} respectively. Scales such as the ones mentioned in table~\ref{tab:subcreat} should be used to fill each cell of the grid. 

The process of evaluating or interpreting an artefact consists of three steps inspired by Jordanous' \ac{SPECS} model (see chapter~\ref{s:specs}\marginpar{§~\ref{s:specs}}) as shown below.

\begin{description}[leftmargin=2cm]
  \item[Step 1] Create master matrix to measure against.
  \item[Step 2] Fill matrix, ideally by several judges.
  \item[Step 3] Check against matrix from step 1.
\end{description}

This system would be useful in scenarios such as art competitions or funding bodies which have a clear outline of requirements or themes which artists address in their artefacts. Alternatively this could be used without step 1 if a more open judgement is needed. Generally, the interpretation/evaluation matrix should be able to address issues such as:

\begin{itemize}
  \item The design of the product might be very innovative but the process that was used was quite established and old.
  \item The person might have been a novice initially but because the time frame of the project was \num{5} years (which would influence the skill of the person towards the end).
  \item The product might be interactive which triggers a lot of emergent behaviour whereas the process itself was very minimal.
  \item The place may play a specific role with the final product but not at all during the development process.
  \item The process might involve some random elements but the concept was very purposive.
  \item The target group may have been very specific whereas the process was very generic.
  \item The process may be an established algorithm but it was used for a non-standard novel purpose.
\end{itemize}


\subsubsection{An example application}

\begin{figure}[!htbp] % (here, top, bottom, page)
  \centering
  \begin{tikzpicture}
  \draw[help lines] (0,0) grid (7,5);

  \node [anchor=east] at (-0.2,4.5) {Place};
  \node [anchor=east] at (-0.2,3.5) {Person};
  \node [anchor=east] at (-0.2,2.5) {Purpose};
  \node [anchor=east] at (-0.2,1.5) {Process};
  \node [anchor=east] at (-0.2,0.5) {Product};

  \node [rotate=90, anchor=west] at (0.5,5.2) {Novelty};
  \node [rotate=90, anchor=west] at (1.5,5.2) {Quality};
  \node [rotate=90, anchor=west] at (2.5,5.2) {Value};
  \node [rotate=90, anchor=west] at (3.5,5.2) {Purpose};
  \node [rotate=90, anchor=west] at (4.5,5.2) {Spatial};
  \node [rotate=90, anchor=west] at (5.5,5.2) {Temporal};
  \node [rotate=90, anchor=west] at (6.5,5.2) {Ephemeral};

  \node at (0.5,0.5) {7}; % Product Novelty
  \node at (1.5,0.5) {6.5}; % Product Quality
  \node at (2.5,0.5) {2}; % Product Value
  \node at (3.5,0.5) {2}; % Product Purpose
  \node at (4.5,0.5) {8}; % Product Spatial
  \node at (5.5,0.5) {7}; % Product Temporal
  \node at (6.5,0.5) {7}; % Product Ephemeral

  \node at (0.5,1.5) {2}; % Process Novelty
  \node at (1.5,1.5) {6}; % Process Quality
  \node at (2.5,1.5) {4}; % Process Value
  \node at (3.5,1.5) {4}; % Process Purpose
  \node at (4.5,1.5) {8}; % Process Spatial
  \node at (5.5,1.5) {8}; % Process Temporal
  \node at (6.5,1.5) {6}; % Process Ephemeral 

  \node at (0.5,2.5) {3}; % Purpose Novelty
  \node at (1.5,2.5) {6}; % Purpose Quality
  \node at (2.5,2.5) {2}; % Purpose Value
  \node at (3.5,2.5) {8}; % Purpose Purpose
  \node at (4.5,2.5) {8}; % Purpose Spatial
  \node at (5.5,2.5) {9}; % Purpose Temporal
  \node at (6.5,2.5) {7}; % Purpose Ephemeral 

  \node at (0.5,3.5) {2}; % Person Novelty
  \node at (1.5,3.5) {8.5}; % Person Quality
  \node at (2.5,3.5) {2}; % Person Value
  \node at (3.5,3.5) {8}; % Person Purpose
  \node at (4.5,3.5) {2.5}; % Person Spatial
  \node at (5.5,3.5) {7}; % Person Temporal
  \node at (6.5,3.5) {5}; % Person Ephemeral 

  \node at (0.5,4.5) {2}; % Place Novelty
  \node at (1.5,4.5) {9}; % Place Quality
  \node at (2.5,4.5) {9}; % Place Value
  \node at (3.5,4.5) {8}; % Place Purpose
  \node at (4.5,4.5) {8.5}; % Place Spatial
  \node at (5.5,4.5) {8.5}; % Place Temporal
  \node at (6.5,4.5) {1}; % Place Ephemeral 
  
  \end{tikzpicture}
\caption[Example completed numerical matrix]{Example completed numerical matrix}
\label{fig:exmatrix}
\end{figure}

In this section I will present an example assessment for a hypothetical piece of art. Let's assume that the scales are represented numerically from 0 to 10 (see figure~\ref{fig:exmatrix}\marginpar{\faicon{object-group}~\ref{fig:exmatrix}}), although they could equally be represented by a colour spectrum from red to blue for example to remove the sense of value judgments\marginpar{\faicon{object-group}~\ref{fig:excmatrix}} (see figure~\ref{fig:excmatrix}), keeping in mind scales as shown in table~\ref{tab:subcreat}\marginpar{\faicon{table}~\ref{tab:subcreat}}. 

% These scales might look like this:

% \noindent \textbf{PRODUCT}:\\
% \itab{Established} \tab{---------------x-----} \stab{Novel}\\
% \itab{Playful} \tab{--------------x------} \stab{Purposive}\\
% \itab{Minimal} \tab{----x----------------} \stab{Complex}\\
% \itab{Emotive} \tab{----x----------------} \stab{Thoughtful}\\
% \itab{Universal} \tab{----------------x----} \stab{Specific}\\
% \itab{Instant} \tab{--------------x------} \stab{Persistent}\\
% \itab{Accidental} \tab{-------------x-------} \stab{Experimental}\\

% \noindent \textbf{PROCESS}:\\
% \itab{Established} \tab{---x-----------------} \stab{Novel}\\
% \itab{Playful} \tab{------------x--------} \stab{Purposive}\\
% \itab{Minimal} \tab{--------x------------} \stab{Complex}\\
% \itab{Emotive} \tab{-------x-------------} \stab{Thoughtful}\\
% \itab{Universal} \tab{----------------x----} \stab{Specific}\\
% \itab{Instant} \tab{----------------x----} \stab{Persistent}\\
% \itab{Accidental} \tab{------------x--------} \stab{Experimental}\\

% \noindent \textbf{PURPOSE}:\\
% \itab{Established} \tab{------x--------------} \stab{Novel}\\
% \itab{Playful} \tab{-------------x-------} \stab{Purposive}\\
% \itab{Minimal} \tab{---x-----------------} \stab{Complex}\\
% \itab{Emotive} \tab{----------------x----} \stab{Thoughtful}\\
% \itab{Universal} \tab{-----------------x---} \stab{Specific}\\
% \itab{Instant} \tab{-------------------x-} \stab{Persistent}\\
% \itab{Accidental} \tab{---------------x-----} \stab{Experimental}\\

% \noindent \textbf{PERSON}:\\
% \itab{Established} \tab{---x-----------------} \stab{Novel}\\
% \itab{Playful} \tab{-----------------x---} \stab{Purposive}\\
% \itab{Minimal} \tab{---x-----------------} \stab{Complex}\\
% \itab{Emotive} \tab{----------------x----} \stab{Thoughtful}\\
% \itab{Universal} \tab{----x----------------} \stab{Specific}\\
% \itab{Instant} \tab{--------------x------} \stab{Persistent}\\
% \itab{Accidental} \tab{---------x-----------} \stab{Experimental}\\

% \noindent \textbf{PLACE}:\\
% \itab{Established} \tab{---x-----------------} \stab{Novel}\\
% \itab{Playful} \tab{------------------x--} \stab{Purposive}\\
% \itab{Minimal} \tab{------------------x--} \stab{Complex}\\
% \itab{Emotive} \tab{---------------x-----} \stab{Thoughtful}\\
% \itab{Universal} \tab{-----------------x---} \stab{Specific}\\
% \itab{Instant} \tab{----------------x----} \stab{Persistent}\\
% \itab{Accidental} \tab{--x------------------} \stab{Experimental}\\

\begin{figure}[!htbp] % (here, top, bottom, page)
  \centering
  \begin{tikzpicture}
  [%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    cell/.style={rectangle,draw=black, minimum size=1cm, opacity=0.5},
  ]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \foreach \x in {0,...,6}{
    \foreach \y in {0,...,4}
        \node[cell] at (\x,\y){};
  } 

  \node[cell, fill=red] at (-2,-2) {\textcolor{white}{0}};
  \node[cell, fill=red!90!blue] at (-1,-2) {\textcolor{white}{1}};
  \node[cell, fill=red!80!blue] at (0,-2) {\textcolor{white}{2}};
  \node[cell, fill=red!70!blue] at (1,-2) {\textcolor{white}{3}};
  \node[cell, fill=red!60!blue] at (2,-2) {\textcolor{white}{4}};
  \node[cell, fill=red!50!blue] at (3,-2) {\textcolor{white}{5}};
  \node[cell, fill=red!40!blue] at (4,-2) {\textcolor{white}{6}};
  \node[cell, fill=red!30!blue] at (5,-2) {\textcolor{white}{7}};
  \node[cell, fill=red!20!blue] at (6,-2) {\textcolor{white}{8}};
  \node[cell, fill=red!10!blue] at (7,-2) {\textcolor{white}{9}};
  \node[cell, fill=blue] at (8,-2) {\textcolor{white}{10}};

  \node [anchor=east] at (-0.7,4) {Place};
  \node [anchor=east] at (-0.7,3) {Person};
  \node [anchor=east] at (-0.7,2) {Purpose};
  \node [anchor=east] at (-0.7,1) {Process};
  \node [anchor=east] at (-0.7,0) {Product};

  \node [rotate=90, anchor=west] at (0,4.7) {Novelty};
  \node [rotate=90, anchor=west] at (1,4.7) {Quality};
  \node [rotate=90, anchor=west] at (2,4.7) {Value};
  \node [rotate=90, anchor=west] at (3,4.7) {Purpose};
  \node [rotate=90, anchor=west] at (4,4.7) {Spatial};
  \node [rotate=90, anchor=west] at (5,4.7) {Temporal};
  \node [rotate=90, anchor=west] at (6,4.7) {Ephemeral};

  \node [cell,fill=red!30!blue] at (0,0) {}; % Product Novelty
  \node [cell,fill=red!35!blue] at (1,0) {}; % Product Quality
  \node [cell,fill=red!80!blue] at (2,0) {}; % Product Value
  \node [cell,fill=red!80!blue] at (3,0) {}; % Product Purpose
  \node [cell,fill=red!20!blue] at (4,0) {}; % Product Spatial
  \node [cell,fill=red!30!blue] at (5,0) {}; % Product Temporal
  \node [cell,fill=red!30!blue] at (6,0) {}; % Product Ephemeral

  \node [cell,fill=red!80!blue] at (0,1) {}; % Process Novelty
  \node [cell,fill=red!40!blue] at (1,1) {}; % Process Quality
  \node [cell,fill=red!60!blue] at (2,1) {}; % Process Value
  \node [cell,fill=red!60!blue] at (3,1) {}; % Process Purpose
  \node [cell,fill=red!20!blue] at (4,1) {}; % Process Spatial
  \node [cell,fill=red!20!blue] at (5,1) {}; % Process Temporal
  \node [cell,fill=red!40!blue] at (6,1) {}; % Process Ephemeral 

  \node [cell,fill=red!70!blue] at (0,2) {}; % Purpose Novelty
  \node [cell,fill=red!40!blue] at (1,2) {}; % Purpose Quality
  \node [cell,fill=red!80!blue] at (2,2) {}; % Purpose Value
  \node [cell,fill=red!20!blue] at (3,2) {}; % Purpose Purpose
  \node [cell,fill=red!20!blue] at (4,2) {}; % Purpose Spatial
  \node [cell,fill=red!10!blue] at (5,2) {}; % Purpose Temporal
  \node [cell,fill=red!30!blue] at (6,2) {}; % Purpose Ephemeral 

  \node [cell,fill=red!80!blue] at (0,3) {}; % Person Novelty
  \node [cell,fill=red!15!blue] at (1,3) {}; % Person Quality
  \node [cell,fill=red!80!blue] at (2,3) {}; % Person Value
  \node [cell,fill=red!20!blue] at (3,3) {}; % Person Purpose
  \node [cell,fill=red!75!blue] at (4,3) {}; % Person Spatial
  \node [cell,fill=red!30!blue] at (5,3) {}; % Person Temporal
  \node [cell,fill=red!50!blue] at (6,3) {}; % Person Ephemeral 

  \node [cell,fill=red!80!blue] at (0,4) {}; % Place Novelty
  \node [cell,fill=red!10!blue] at (1,4) {}; % Place Quality
  \node [cell,fill=red!10!blue] at (2,4) {}; % Place Value
  \node [cell,fill=red!20!blue] at (3,4) {}; % Place Purpose
  \node [cell,fill=red!15!blue] at (4,4) {}; % Place Spatial
  \node [cell,fill=red!15!blue] at (5,4) {}; % Place Temporal
  \node [cell,fill=red!90!blue] at (6,4) {}; % Place Ephemeral 
  
  \end{tikzpicture}
\caption[Example completed colour matrix]{Example completed colour matrix}
\label{fig:excmatrix}
\end{figure}

Ideally, these scales would need to be applied by several judges during the evaluation process, generating an intuitive assessment of the various values (e.g. Playful---Purposive) for each of the criteria (e.g. Product).

\newpage
\section{From the Interpretation to Paris by Sea}

\begin{figure}[!htb]
\centering
  \includegraphics{inter.pdf}
\end{figure}

The first part of this chapter relates to problems brought up by theoretical models of creativity (§~\ref{ch:creativity} \creat, and §~\ref{ch:foundations} \found) and its evaluation (§~\ref{ch:evaluation} \eval) in computers. This is also discussed to an extent in the \nameref{ch:analysis} \anal~ chapter. The second part of this chapter is then concerned with the proposal of one of the original contributions: the evaluation and interpretation framework in section~\ref{s:creatint} \inter. This comes up again in the \nameref{ch:future} \aspi~ chapter.

\begin{figure}[!htb]
\centering
  \includegraphics[width=\textwidth]{legend.pdf}
\end{figure}

\stopcontents[chapters]
