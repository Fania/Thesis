% !TEX root = ../main.tex

\chapter{Patanalysis}
\label{ch:analysis}

\startcontents[chapters]

\vfill

\begin{alltt}\sffamily
Where thou mayst knock a nail into his head,
but near him thy angel becomes a fear,
it must omit real necessities,
hear Faith infringed which such zeal did swear.

With sighs in an odd angle of the isle,
before me to sweet beds of flow,
might quench the zeal of all professors else,
the whilst his iron did on the anvil cool.

Intend a kind of zeal both to the Prince and Claudio,
and threescore year would make the world away,
nay if you read this line.

Have no delight to pass away the time,
by a shadow like an angel,
four nights will quickly dream away the time.
\end{alltt}

\newpage
\minicontents
\spirals

\todo{go over previous chapters incl lit review and refer back to things. bring things together. show the breadth and depth of my research!!!}
\todo{relate all of these things back to my topic of AMC}

\spirals

A lot of the more theoretical aspects of this research have been discussed in chapters~\ref{ch:foundations}\marginnote{§~\ref{ch:foundations}~\&~\ref{ch:interpretation}} and \ref{ch:interpretation}. The evaluation here is more concerned with the practical artefact \url{pata.physics.wtf} and its interpretation.

The chapter is divided into several sections addressing issues related to \url{pata.physics.wtf}. This includes a discussion of the inspirations, an analysis of some of the technical aspects, a review of design decisions made, a contextualisation and also a meta-analysis of the project's execution and management.


\section{Influences}

Looking back over the inspirations for this project described in chapter~\ref{ch:inspirations}\marginnote{§~\ref{ch:inspirations}}, some of the influences can be clearly seen straight away. Others are intentionally a bit more subtle. There are various motivations for that. First, transparency conflicts with surprise. \emph{Serendipity} was one of the original aims to try and model, so being overly obvious and descriptive about what the tool is and does would be counter productive. An element of surprise also makes it more enjoyable in repeat visits. Pure randomness is meaningless. Another reasons was \emph{humour}. Pataphysics has an intrinsic kind of humour I wanted to include in the whole presentation of the artefact. 

\begin{description}
  \item[Syzygy Surfer]\marginnote{§~\ref{s:surfer}} The influence of the Syzygy Surfer cannot be overstated. It forms the immediate predecessor to my research. The authors of the Syzygy Surfer are part of my supervisory team. This is where the initial ideas for the pataphysical algorithms\marginnote{§~\ref{s:algorithms}} came from. There are important differences as well though. For example, pataphors were never implemented as originally suggested. The idea of using ontologies and semantic web technologies such as \ac{RDF} to develop the system was abandoned early on too.
  \item[Faustroll Library]\marginnote{§~\ref{s:faustlib}} This fictional library of real books was direct inspiration for the Faustroll corpus used in the text search\marginnote{§~\ref{s:corpora}}. I tried my best to complete the library as accurately as I could but some of the texts where unsourceable. As with the original, I included some foreign language texts. Since the results (if the Faustroll corpus is chosen of course) are drawn from any of these texts, the mood and style of language is quite distinct and atmospheric.
  \item[Queneau's $\bm{10^{14}}$ poems]\marginnote{§~\ref{s:queneau}} Queneau is another one of the inspirations that became a direct influence. The text search can be displayed as poetry\marginnote{§~\ref{s:poetry}} in the same style as Queneau's \num{100} thousand million poems only in digital form and with a larger set of lines. This means that many more possible poems can be generated by switching individual lines. The outcome is beautiful.
  \item[Chinese Encyclopedia]\marginnote{§~\ref{s:borges}} Borges story has been an inspiration right from the start. The subtle humour in it is great. The sort of semantic logic behind it was modeled through the pataphysical algorithms\marginnote{§~\ref{s:algorithms}}.
  \item[Yossarian]\marginnote{§~\ref{s:yossarian}} The metaphorical algorithms are intriguing but elusive---I wasn't able to find any details on their implementation. This may be due to the nature of the project, which is commercial rather than academic. It is hard to compare against this site as it is so different even though we share some of the same goals or principles.
  \item[Library of Babel]\marginnote{§~\ref{s:babel}} The library of babel is a great project which has only indirectly influence my work. The pataphysical elements in it are obvious even though perhaps unconscious. The seriousness with which the library is presented, the pseudo-scientific approach, the vagueness of what's actually behind it. Is it random? Or is it indeed the most gigantic digital library of any book every written or even to be written? The sheer perceived scale of the library was part motivation for calculating the numbers of the generatable poems\marginnote{\faicon{table}~\ref{tab:faustshake}}.
  \item[Oulipo]\marginnote{§~\ref{s:oulipo}} Given that the \ac{OULIPO} is directly rooted in pataphysical principles\footnote{Remember that the \ac{OULIPO} was founded as a subcommittee of the ``Coll\`{e}ge de \'Pataphysique'' in the 60's.}, the influence on this project cannot be underestimated. The algorithms\marginnote{§~\ref{s:algorithms}} created could even be seen as an oulipian technique themselves.
  \item[Coder Culture]\marginnote{§~\ref{s:culture}} This group of inspirations is a bit more generic and influenced lots of little things throughout the project. The idea of hiding easter eggs on the site, the deliberate placement or use of errors, the obfuscation, the humour, the jargonisation and littered `l33t' style language, and the art and aesthetics behind it. All of that was influenced by coder culture---and most of all perhaps: this thesis.
\end{description}


\section{Pataphysicalisation}

As mentioned in chapter~\ref{s:pataputers}\marginnote{§~\ref{s:pataputers}},tThe internal transformation of a query term to the final results is what I called the \emph{pataphysicalisation} process. The three pataphysical algorithms (Clinamen, Syzygy and Antinomy), or \emph{patalgorithms}, are at the center of this process. 

\begin{enumerate}
  \item User enters single query term,
  \item system transforms query term into list of pataphysicalised terms,
  \item system retrieves sentence fragments containing keywords from this list,
  \item system displays sentence fragments in various formats.
\end{enumerate}

It is quite interesting to compare the algorithms with each other. By removing the clutter (in this case the sentence surrounding the pataphysicalised keyword) we can see a few example results side by side below in table~\ref{tab:algorithmscomp}.

\begin{table}[!htbp]
\caption[Comparison of patalgorithms]{Comparison of patalgorithms showing a selection of results for each}
\label{tab:algorithmscomp}
  \begin{tabu}{X[1,L]X[3,L]X[3,L]X[2,L]}
  \toprule
  % \cline{2-4}
  \textbf{Query} & \textbf{Clinamen} & \textbf{Syzygy} & \textbf{Antinomy}
  \\ \midrule
  \textbf{clear}
  &
  altar, leaf, pleas, cellar
  &
  vanish, allow, bare, pronounce
  &
  opaque
  \\ \cmidrule{1-4}
  \textbf{solid}
  &
  sound, valid, solar, slide
  &
  block, form, matter, crystal, powder
  &
  liquid, hollow
  \\ \cmidrule{1-4}
  \textbf{books}
  &
  boot, bones, hooks, rocks, banks
  &
  dialogue, authority, record, fact
  &
  ---
  \\ \cmidrule{1-4}
  \textbf{troll}
  &
  grill, role, tell
  &
  wheel, roll, mouth, speak
  &
  ---
  \\ \cmidrule{1-4}
  \textbf{live}
  &
  love, lies, river, wave, size, bite
  &
  breathe, people, domicile, taste, see, be
  &
  recorded, dead
  \\ \bottomrule
  \end{tabu}
\end{table}

Seeing the results in a table like\marginnote{\faicon{table}~\ref{tab:algorithmscomp}} this gives an almost immediate idea of how each algorithm works. This is not meant to be transparent and perhaps only after knowing the ins and outs of the algorithms can one recognise how each result was found. 

The clinamen results show words that contain one or two spelling errors of the original query term. It is perhaps counter-intuitive to have words such as `altar', `leaf' and `cellar' be classed as spelling errors of the word `clear' but they clearly could be. Remember that a spelling error can be classed in one of four ways: (1) deletion, (2) insertion, (3) substitution and (4) transposition. So, going from `clear' to `altar' is an instance of two times case 3 (`c' is replace by `a' and `e' is replaced by `t') and going from  `clear' to `leaf' is an example of case 1 (`c' is deleted) and case 3 (`r' is replaced by `f').

Looking at the second column (the syzygy results) shows the semantic relationship between the original query term and the results. Again, this may not be immediately noticeable but certainly once you know how the process works you can recognise the common relations. This is especially evident for the antinomy algorithm which is based on opposites.

\spirals

However it is equally interesting to compare some full sentences. Looking at some of the poems at the beginning of each chapter shows the variety of the possible outcomes (see pages \pageref{ch:introduction}, \pageref{ch:inspirations}, \pageref{ch:methodology}, \pageref{ch:pataphysics}, \pageref{ch:creativity}, \pageref{ch:technology}, \pageref{ch:evaluation}, \pageref{ch:foundations}, \pageref{ch:interpretation}, \pageref{ch:implementation}, \pageref{ch:applications}, \pageref{ch:analysis}, \pageref{ch:aspirations}, and \pageref{ch:observations}). It also highlights the difference between the two corpora. Poems based on the Faustroll corpus have a very different sound and feel to it than ones based on the Shakespeare corpus.

\begin{figure}[!htbp]
\centering
\begin{minipage}{.45\linewidth}
  \settowidth{\versewidth}{earth was flat like the floor of an Oven}
  % \PoemTitle{Flower}
  \begin{verse}[\versewidth]\sffamily\footnotesize
    There was a period put to the Fire\\
    pink and spot\\
    earth was flat like the floor of an Oven\\
    as much ease as a mower doth the grass

    during the first period of my captivity\\
    room with a hard earthen floor\\
    not within everyone's power\\
    or your favourite flowers died

    shocks lose power\\
    the white daisy\\
    after a long period

    poppy\\
    peony\\
    stock to all People
  \end{verse}
\end{minipage}
\hspace{.02\linewidth}
\begin{minipage}{.45\linewidth}
  \settowidth{\versewidth}{led by their master to the flow'red fields}
  % \PoemTitle{Flower}
  \begin{verse}[\versewidth]\sffamily\footnotesize
    O bloody period\\
    I as your lover speak\\
    has she such power\\
    gather those flowers

    thy lover\\
    juiced flowers\\
    had I been any god of power\\
    or a lover's lute

    the river hath thrice flow'd\\
    but sad mortality o'ersways their power\\
    now here a period of tumultuous broils

    led by their master to the flow'red fields\\
    not a minister in his power\\
    where soulds do couch on flowers
  \end{verse}
\end{minipage}
\caption[Faustroll vs. Shakespeare poetry]{Comparison of Faustroll (left) versus Shakespeare (right) poetry, both for query term `flower'}
\label{fig:2poems}
\end{figure}

Sometimes we can even get a general feel for the theme of the poem, as in we can recognize the connection, the relationship between the individual lines and what must be the original query term. Of course putting the poems into the chapters as they are---without specifically stating the keyword they were generated from or the corpus they are based on---makes them a bit more elusive.

The different language is quite obvious. This is helped by the fact that the Shakespeare corpus is of course written by the same author\footnote{Unless of course we believe the legends that Shakespeare didn't write those works by himself\ldots}. The Faustroll corpus contains text by over \num{20} different authors and in three different languages even.


\subsection{Numbers}
\label{s:numbers}

The above examples (table~\ref{tab:algorithmscomp} and figure~\ref{fig:2poems} give a good overview of the two main factors in the pataphysicalisation process, namely the three patalgorithms and the two corpora. Both only reflect a small selection of the variety of results produced though. It is therefore quite interesting to look at some actual numbers.

\begin{table}[!htbp]
\caption[Faustroll vs Shakespeare in numbers]{Faustroll versus Shakespeare in numbers}
\label{tab:faustshake}
  \centering
  \begin{tabu}{llcccc}
  \toprule
  \textbf{Query} & \textbf{Corpus} & \textbf{Results} & \textbf{Reverbs} & \textbf{Origins} & \textbf{Poems}\\
  \midrule
  \multirow{2}{*}{flower} & Faustroll   & \num{90}   & \num{25} & \num{18} & \num{7.8e10}\\
                          & Shakespeare & \num{158}  & \num{15} & \num{38} & \num{3.8e14}\\
  \cmidrule{1-6}
  \multirow{2}{*}{clear}  & Faustroll   & \num{542}  & \num{79} & \num{23} & \num{1.3e22}\\
                          & Shakespeare & \num{1445} & \num{72} & \num{38} & \num{1.5e28}\\
  \cmidrule{1-6}
  \multirow{2}{*}{troll}  & Faustroll   & \num{124}  & \num{16} & \num{16} & \num{4.4e12}\\
                          & Shakespeare & \num{327}  & \num{14} & \num{38} & \num{1.1e19}\\
  \cmidrule{1-6}
  \multirow{2}{*}{fania}  & Faustroll   & \num{9}    & \num{2}  & \num{6}  & \num{1}\\
                          & Shakespeare & \num{15}   & \num{2}  & \num{14} & \num{1}\\
  \bottomrule
  \end{tabu}
\end{table}

Table~\ref{tab:faustshake}\marginnote{\faicon{table}~\ref{tab:faustshake}} shows a comparison of the two different corpora with four example query terms.

\begin{description}
  \item[Results] A `result' in this case is one line (a sentence fragment). This column shows the total number of results found by the three algorithms combined. Individual results appear only once but the keyword in contains can appear in several of the results.
  \item[Reverbs] A `reverberation' is one of the terms in the list of keywords produced by the pataphysicalisation process. The list cannot contain duplicates but each reverberation cab appear in more than one result. Reverberations are used to find results in each corpus. This column shows the total number of reverberations created by the three algorithms.
  \item[Origins] An `origin' in this case is the original source text from which a given sentence fragment was retrieved. Each corpus has a set number of source texts. Each origin can contain several results based on several reverberations. This column shows the number of origins in the given corpus in which results where found.
  \item[Poems] This refers to the total number of Queneau style poems that can be generated using the given results\footnote{The original book by Queneau contains \num{10} sonnets with \num{14} lines each. This means the total number of possible poems generated by different combinations of lines in the book is $10^{14}$ or one hundred thousand million.}. This is calculated as the number of different options per line to the power of the number of lines.
\end{description}

To put this into perspective, the Faustroll corpus contains a total of \num{28} texts of very varied authors and different languages even. This might explain why not the queries in table~\ref{tab:faustshake}\marginnote{\faicon{table}~\ref{tab:faustshake}} have not found results in all of the texts. The query `clear' found results in \num{23} out of \num{28} for example while the query `fania' only found results in \num{6} texts. The Shakespeare corpus seems much more uniform. Reverberations generally seem to find results in all \num{38} source texts in the corpus apart from the query `fania'. This might be explained by the fact that Shakespeare wrote all of the texts himself using much of the same language and vocabulary unlike the Faustroll corpus. 

It is rather interesting to note that even though the Shakespeare corpus produces overall more results from more texts, the Faustroll corpus produces more reverberations per query. This might stem from the multi-author, multi-language nature of the corpus. The overall vocabulary\marginnote{§~\ref{s:index}} used is much larger than the Shakespeare one.

Regarding the final column showing the number of possible poems, let's look at the Shakespeare---clear row. There are \num{1445} number of results. These are spread over \num{14} lines, so each line has \num{103} options. The overall number of poems is therefore calculated as $103^{14}$ which equals \num{15125897248551112432256145169} (or \num{1.5e28} in short\marginnote{\faicon{table}~\ref{tab:faustshake}}).

\spirals

A slightly different angle to consider is a comparison of these kind of numbers between each of the algorithms. Table~\ref{tab:algonums}\marginnote{\faicon{table}~\ref{tab:algonums}} shows the numbers of results, reverberations and origins for the Clinamen, Syzygy and Antinomy algorithms using four example query terms (`clear', `shine', `disorder' and `stuck') for each of the two corpora (`Faustroll' and `Shakespeare').

% \todo{add french query term cœur}
\begin{table}[!htbp]
\caption[Numbers per algorithm]{Results-Reverberations-Origin numbers per algorithm}
\label{tab:algonums}
\centering\small
\begin{tabu}{ll|ccc|ccc|ccc|ccc}
\toprule
 & & \multicolumn{3}{c}{\textbf{Clinamen}} & \multicolumn{3}{c}{\textbf{Syzygy}} & \multicolumn{3}{c|}{\textbf{Antinomy}} & \multicolumn{3}{c}{} \\ 
\cmidrule{3-11}
\multicolumn{1}{l}{} & \textbf{Query} & \rotatebox{90}{Results} & \rotatebox{90}{Reverbs} & \rotatebox{90}{Origins} & \rotatebox{90}{Results} & \rotatebox{90}{Reverbs} & \rotatebox{90}{Origins} & \rotatebox{90}{Results} & \rotatebox{90}{Reverbs} & \rotatebox{90}{Origins} & \multicolumn{3}{c}{\textbf{Total}} \\ 
\midrule
\multicolumn{1}{l}{\multirow{4}{*}{\textbf{\rotatebox{90}{Faustroll}}}} 
& clear & 158 & 20 & 13 & 368 & 90 & 23 & 16 & 8 & 8 & \multicolumn{3}{c}{542--79--23} \\
\multicolumn{1}{l}{} 
& shine & 228 & 29 & 19 & 154 & 61 & 16 & 0 & 0 & 0 & \multicolumn{3}{c}{382--61--20} \\
\multicolumn{1}{l}{}
& disorder & 0 & 0 & 0 & 159 & 127 & 23 & 10 & 2 & 10 & \multicolumn{3}{c}{169--40--23} \\
\multicolumn{1}{l}{}
& stuck & 59 & 14 & 13 & 181 & 43 & 22 & 11 & 3 & 9 & \multicolumn{3}{c}{251--47--22} \\ 
\multicolumn{1}{l}{}
& feather & 78 & 13 & 12 & 83 & 37 & 14 & 0 & 0 & 0 & \multicolumn{3}{c}{161--29--14} \\[0.5cm] 
\cmidrule{1-12}
\multicolumn{1}{l}{\multirow{4}{*}{\textbf{\rotatebox{90}{Shakespeare}}}}
& clear & 435 & 20 & 38 & 997 & 90 & 38 & 13 & 8 & 12 & \multicolumn{3}{c}{1445--72--38} \\
\multicolumn{1}{l}{}
& shine & 575 & 29 & 38 & 333 & 61 & 38 & 0 & 0 & 0 & \multicolumn{3}{c}{908--53--38} \\
\multicolumn{1}{l}{}
& disorder & 0 & 0 & 0 & 326 & 127 & 38 & 29 & 2 & 29 & \multicolumn{3}{c}{355--26--38} \\
\multicolumn{1}{l}{}
& stuck & 152 & 14 & 37 & 479 & 43 & 38 & 34 & 3 & 34 & \multicolumn{3}{c}{665--41--38} \\ 
\multicolumn{1}{l}{}
& feather & 217 & 13 & 38 & 195 & 37 & 38 & 0 & 0 & 0 & \multicolumn{3}{c}{412--25--38} \\ 
\bottomrule
\end{tabu}
\end{table}

The first immediate observation surely must be that the Antinomy algorithm produces the fewest results, in two cases even none at all. This is caused by the fact that the Antinomy algorithm\marginnote{§~\ref{s:antinomy}} is based on semantic opposites in WordNet and some words simply do not have defined opposites. Addressing this issue was left for future work mentioned in chapter~\ref{ch:future}\marginnote{§~\ref{ch:future}}. On the other hand the Syzygy algorithm\marginnote{§~\ref{s:syzygy}}, which is also based on WordNet, produces most results on average.

The Clinamen algorithm\marginnote{§~\ref{s:clinamen}} interestingly produces a varying number of results depending on the query term. For the query `disorder' no results where found in either the Faustroll or the Shakespeare corpus. This of course is rooted in the fact that no reverberations where produced during the pataphysicalisation process. Here it is important to remember that the Clinamen algorithm makes use of a base document\footnote{This is hardcoded to be Jarry's \textit{Exploits and Opinions of Doctor Faustroll, Pataphysician}. Section~\ref{s:basetext} discusses what would happen if we changed the base document to something else.}\marginnote{§~\ref{s:basetext}}. Therefore the success of the algorithm depends on the vocabulary of this base text. In this particular example this means that there was no word in the base text of one or two spelling errors to the original query of `disorder'.

Looking at the origins column in table~\ref{tab:algonums}\marginnote{\faicon{table}~\ref{tab:algonums}} highlights how the Shakespeare corpus mostly produces results from each of its \num{38} texts. The Faustroll corpus varies a lot more. This may be due to the different languages and varying word counts of the files in the corpus.

\paragraph*{Faustroll}
\begin{itemize}
\vspace{-0.5cm}
  \item There are three empty texts (Peladan, de Chilra, de Regnier).
  \item The total number of words is \num{1738461}. Of this, \num{1204158} words are from English texts (70\%), \num{497144} are French (28\%) and \num{37159} are in German (2\%).
  \item The shortest text contains \num{3853} words (Coleridge).
  \item The longest text contains \num{419456} words (Poe).
  \item The average amount of words per text is \num{62088}.
  \item The vocabulary of the index contains \num{78893} words. Of this \num{49040} are English terms.
\end{itemize}

\paragraph*{Shakespeare}
\begin{itemize}
\vspace{-0.5cm}
  \item The total number of words is \num{883460}\footnote{According to \autocite{Efron1976} Shakespeare used \num{31534} different words in his works, about half of which he only used once (\num{14376}). They cite the total number of words used in his corpus as \num{884647}.}.
  \item The shortest text contains \num{2568} words (Lover's Complaint).
  \item The longest text contains \num{32031} words (Hamlet).
  \item The average amount of words per text is \num{23249}.
  \item The vocabulary of the index contains \num{23398} words.
\end{itemize}

It should be noted that the index\marginnote{§~\ref{s:index}} is generated based on the texts vocabulary minus stopwords. Stopwords (e.g. `and', `or', `the', etc.) are common terms that occur frequently in use. The full list of stopwords per language can be found in appendix~\ref{app:stopwords}\marginnote{§~\ref{app:stopwords}}.


\subsection{Sentences}
\label{s:sents}

The index stores entries in the following format (for more detail see chapter~\ref{s:index}\marginnote{§~\ref{s:index}}).

\begin{minted}{text}
{
  word1: {fileA: [pos1, pos2, ...], fileB: [pos1], ...},
  word2: {fileC: [pos1, pos2], fileK: [pos1, pos2, pos3, ...], ...},
  ...
}
\end{minted}

At the top level we have a list of words. Each word contains a list of files and each file stores a list of positions. After the pataphysicalisation process, any entries in the index that match the pataphysicalised query terms are looked up and then the corresponding sentences are retrieved to display as results. The code is set up to retrieve the first position only instead of each one, referred to as the \emph{first only} method from now on (see source~\ref{code:ppsent}\marginnote{\faicon{code}~\ref{code:ppsent}}).

\begin{minted}{text}
{
  word1: {fileA: [pos1], fileB: [pos1], ...},
  word2: {fileC: [pos1], fileK: [pos1], ...},
  ...
}
\end{minted}

This has two implications: (1) there is some unnecessary computation at the startup of the program when then index is generated and (2) only a fraction of the possible results are retrieved.

The decision to only use one position was mainly made for performance issues. Generating the full results with each position (the \emph{return all} method) takes a lot more time than doing it for just the first occurance. This is perhaps best understood by looking at an example.

The Faustroll corpus produces \num{542} results for the query `clear' with only the first sentence. If we enable the retrieval of every matching sentence, the number of results increases to \num{8751}.

\begin{minted}{text}
cellar: {l_19: [4448, 18718, 68678, 110318, 192486, 267241, 352502, 352565]}
\end{minted}

The above pseudocode shows an entry for the word `cellar' with only the positions for the \py{l_19} file\footnote{Francois Rabelais: Gargantua and Pantagruel}. Another example of an index entry for the term `doctor' can be found on page~\pageref{c:pos}. The sentences for the above positions are shown below. Using only the first occurance (position) means the system ignores the rest.

\begin{itemize}
  \item ``rope wine is let down into a cellar''
  \item ``bread and holy water of the cellar''
  \item ``year who had a cool cellar under ground''
  \item ``cellar''
  \item ``that Nick in the dark cellar''
  \item ``on the cellar door''
  \item ``in mind of the painted cellar in the oldest city in the world''
  \item ``and the painted cellar also''
\end{itemize}

Table~\ref{tab:percent}\marginnote{\faicon{table}~\ref{tab:percent}} shows some example queries for both corpora and the number of results retrieved with the first position only used (as in the live version of \url{pata.physics.wtf}) in column 5 and on column 3 with all results retrieved. The final column shows what percentage of results are retrieved using the `first only' method. The average percentage for this is about 10\%. 

\begin{table}[!htbp]
\caption[Count and time of results]{Count, time and percentage of results retrieved}
\label{tab:percent}
  \centering
  \begin{tabu}{llccccc}
  \toprule
  & & \multicolumn{2}{c}{\textbf{Return all}} & \multicolumn{2}{c}{\textbf{First only}} & \\
  \cmidrule{3-4}\cmidrule{5-6}
  \textbf{Query} & \textbf{Corpus} & \textit{Count} & \textit{Time} & \textit{Count} & \textit{Time} & \textbf{Percent} \\
  \midrule
  \multirow{2}{*}{clear} 
  & Faustroll   & \num{8751}  & 59s   & \num{542}  & 1.83s & 6.19\%  \\
  & Shakespeare & \num{11304} & 69.2s & \num{1445} & 3.59s & 12.78\% \\
  \cmidrule{1-7}
  \multirow{2}{*}{solution} 
  & Faustroll   & \num{693}   & 11.7s & \num{53}   & 0.98s & 7.65\%  \\
  & Shakespeare & \num{547}   & 8.51s & \num{86}   & 1.07s & 15.72\% \\
  \cmidrule{1-7}
  \multirow{2}{*}{form} 
  & Faustroll   & \num{19222} & 120s  & \num{1064} & 2.81s & 5.54\%  \\
  & Shakespeare & \num{13635} & 90s   & \num{2125} & 4.63s & 15.58\% \\
  \cmidrule{1-7}
  \multirow{2}{*}{record}
  & Faustroll   & \num{5199}  & 38s   & \num{275}  & 1.72s & 5.29\%  \\
  & Shakespeare & \num{7631}  & 49.2s & \num{794}  & 2.09s & 10.40\% \\ 
  \bottomrule
  \end{tabu}
\end{table}

Google recommends having a ``response time under \num{200}ms''\footnote{\url{https://developers.google.com/speed/docs/insights/Server}}. The numbers in table~\ref{tab:percent}\marginnote{\faicon{table}~\ref{tab:percent}} clearly show that the `return all' method is unacceptable in terms of speed performance. Using the `first only' method is much closer to the recommended speed limit. Columns 4 and 6 show the time it takes for the page to load from the user query to the display of results. The times are shown in seconds. The data for column 4 was generated using a Chrome browser plugin called ``Load-timer'' by alex-vv\footnote{\url{https://github.com/avflance/chrome-load-timer}} and the data for column 6 was generated by the Chrome ``Developer Tools''.


\subsection{Index}
\label{s:analindex}

The index\marginnote{§~\ref{s:index}} is a central part of the \url{pata.physics.wtf} system. It is generated when the program/server is first started up but then cached and re-used. The initial process of going over all the text files in each corpus takes a few minutes. Of course in comparison to a full Internet crawl this is a tiny amoutn of data to be processed. 

The Faustroll corpus\marginnote{§~\ref{s:corpora}} for example contains \num{28} texts\footnote{This is technically not true since a few of those files are empty.}. Individually they are small plaintext files of sizes between 24KB (Coleridge) and 2MB (Poe). This is of course caused by the nature of some of these texts. Samuel Coleridge's \textit{The Rime of the Ancient Mariner} is a poem whereas the Edgar Allan Poe file contains a collection of all of his works. The total size of the Faustroll corpus is 10MB. The Shakespeare corpus is much more evenly distributed as all of his works are separated out into individual text files of an average size of around 150KB. The total size of the Shakespeare corpus is only 5.3MB.

Now, the size of the actual index data structure is interesting. Processing the Faustroll corpus alone produced an index of 12.4MB. That's larger than the actual size of the corpus. Remember, the index contains each word that occurs anywhere in the corpus together with the list of files it is found in and the specific locations within each text. This includes English words buts also French and German terms since the Faustroll corpus is multi-lingual. The combined index is therefore 35.2MB large.

Figure~\ref{fig:termdocs}\marginnote{\faicon{object-group}~\ref{fig:termdocs}} shows some example words and how often they occur in three example files of the Faustroll corpus in the form of a \ac{TDM} (see chapter~\ref{ch:technology} for more details). Implementing the Faustroll corpus index as a \ac{TDM} properly, would result in a $78893 \times 28$ matrix---the number of words (not counting duplicates) times the number of files in the corpus.

\spirals

As mentioned before\marginnote{§~\ref{s:index}}, the index is structured in a double nested dictionary style list as shown below.

\begin{minted}{text}
{
  word1: {fileA: [pos1, pos2, ...], fileB: [pos1], ...},
  word2: {fileC: [pos1, pos2], fileK: [pos1, pos2, pos3, ...], ...},
  ...
}
\end{minted}

There are other options of how to make this data structure. For example we could store a list of pataphysicalised query terms (\emph{patadata}) with each word and the full sentence fragment with each position. This would allow faster retrieval at query time but would increase the time needed for the initial startup. Additionally we could store data on rhyming patterns directly in the index with each word entry. This would of course be beneficial for the implementation of a rhyming scheme for the poetry generation. See also chapter~\ref{ch:future}\marginnote{§~\ref{ch:future}}.

\begin{minted}{text}
{
  word1: ([patadata], [rhymes], {fileA: [(pos1, sent), (pos2, sent), ...], fileB: [(pos1, sent)], ...}),
  word2: ([patadata], [rhymes], {fileC: [(pos1, sent), (pos2, sent)], fileK: [(pos1, sent), (pos2, sent), (pos3, sent), ...]), ...},
  ...
}
\end{minted}

\spirals

As a comparison to the \num{35} megabyte index generated by the system described in this thesis, and the search times mentioned in table~\ref{tab:percent}\marginnote{\faicon{table}~\ref{tab:percent}}, Google claims to have ``well over \num{100000000} gigabytes'' of data in their index and that they've spent ``over one million computing hours to build it''. Similarly Google managed to retrieve about \num{2140000000} results for the query `clear' in 0.85 seconds.

\begin{quotation}
  The web is like an ever-growing public library with billions of books and no central filing system. Google essentially gathers the pages during the crawl process and then creates an index, so we know exactly how to look things up. Much like the index in the back of a book, the Google index includes information about words and their locations. When you search, at the most basic level, our algorithms look up your search terms in the index to find the appropriate pages.

  The search process gets much more complex from there. When you search for ``dogs'' you don't want a page with the word ``dogs'' on it hundreds of times. You probably want pictures, videos or a list of breeds. Google's indexing systems note many different aspects of pages, such as when they were published, whether they contain pictures and videos, and much more.\sourceatright{\autocite{GoogleCI}}
\end{quotation}

It is also worth noting that Google for example also uses a form of pataphysicalisation. In their case of course the aim of the pataphysicalisation isn't to infuse the result with pataphysics but to make it more relevant and interesting to users. They use techniques such as PageRank and query expansion to achieve this. See chapter~\ref{ch:technology}\marginnote{§~\ref{ch:technology}} for more information on this.


\subsection{Clinamen}

The clinamen\marginnote{§~\ref{s:clinamenalgo}} function uses the Damerau-Levenshtein algorithm\marginnote{§~\ref{app:damlev}} to create patadata. It also uses the Faustroll text. The way this works is as follows. If the query term is a spelling error of size 1 or 2 of a term in the vocabulary within the faustroll text then it is included in the list of resulting terms. The logic behind this is due to the Damerau-Levenshtein algorithm needing two words to compare with each other. It also ensures we get real words as results and not some random gibberish.

Currently the algorithm is set to accept terms that have a difference of 1 or 2 to the original query. We can lower this to 1 to allow fewer results or increase it to make it broader. I felt 1 or 2 was a good compromise. Only allowing 1 error would mean terms are too similar. Allowing 3 might mean they are drastically different.


\subsubsection{Changing the base text}
\label{s:basetext}

As examples of using different base documents in the Clinamen algorithm I have used three examples. 

\begin{itemize}
  \item \textit{Midsummer Night's Dream} by Shakespeare (`Dream' in short)
  \item \textit{Arabian Nights} by various artists (`Nights' in short)
  \item \textit{Exploits and Opinions of Doctor Faustroll, Pataphysician} by Jarry (`Faustroll' in short)
\end{itemize}

Figure~\ref{fig:changebase}\marginnote{\faicon{table}~\ref{fig:changebase}} shows three tables, each compare the full list of pataphysicalised terms for a particular query term for the three base texts above. These examples show that changing the base text of the algorithm does indeed change the set of results you get. 

The decision to use the Faustroll text as a base text was made due to the central role it has for pataphysics\marginnote{§~\ref{ch:pataphysics}} and indeed the corpus itself. The Faustroll book introduces pataphysics and contains Jarry's original definition and it also lists Dr. Faustroll's library of `equivalent books'\marginnote{§~\ref{s:faustlib}} which was used as the inspiration for the Faustroll corpus.

\begin{figure}[!p]
\centering
\begin{subfigure}[b]{\textwidth}
  \captionof{figure}{Changing base in Clinamen - query `fania'}
  \label{tab:basefania}
  \begin{tabu}{X[l]X[1.5,l]X[l]}
    \toprule
    \textbf{Dream} & \textbf{Nights} & \textbf{Faustroll}\\
    \midrule
    fail, faint, fair, fan, fancy 
    & 
    fail, fain, faint, fair, fancy, Sadia 
    & 
    fan, fans, Tanit\\
    \bottomrule
    \end{tabu}
\end{subfigure}
\vskip\baselineskip
\vskip\baselineskip
\begin{subfigure}[b]{\textwidth}
  \captionof{figure}{Changing base in Clinamen - query `clear'}
  \label{tab:baseclear}
  \begin{tabu}{X[l]X[1.5,l]X[l]}
    \toprule
    \textbf{Dream} & \textbf{Nights} & \textbf{Faustroll}\\
    \midrule
    altar, bear, car, cheer, clean, clear, dear, ear, fear, hear, lead, liar, near, plead, rear, swear, tear, wear 
    & 
    bear, cedar, cellar, cheap, clad, clap, clean, clear, cleared, clearer, clearly, clever, dear, ear, fear, hear, lead, leaf, leap, learn, liar, near, swear, tear, wear, year 
    & 
    altar, cedar, cellar, clad, clean, clear, clearly, dear, ear, fear, hear, lead, leaf, leap, near, pleas, rear, swear, year\\
    \bottomrule
    \end{tabu}
\end{subfigure}
\vskip\baselineskip
\vskip\baselineskip
\begin{subfigure}[b]{\textwidth}
  \captionof{figure}{Changing base in Clinamen - query `moss'}
  \label{tab:basemoss}
  \begin{tabu}{X[l]X[1.1,l]X[1.2,l]}
    \toprule
    \textbf{Dream} & \textbf{Nights} & \textbf{Faustroll}\\
    \midrule
    amiss, ass, boys, costs, cross, dost, fogs, gods, goes, gross, kiss, Less, loos, lose, lost, mask, moan, moans, mock, mole, mood, moon, more, morn, most, mote, mous, mouse, move, musk, must, nose, oes, pass, ress, rose, roses, toys, vows 
    & 
    amiss, ass, bows, boys, cost, cosy, cross, does, dogs, foes, goes, host, hosts, kiss, less, lose, loss, lost, lots, lows, mass, massy, mess, mist, mode, moon, more, Moses, most, mouse, move, moves, musk, must, pass, post, pots, rocs, rose, roses, sobs, sons, vows 
    & 
    ass, Bosse, bows, Boys, cost, costs, cows, cross, does, dogs, ess, fess, gods, goes, host, kiss, less, lose, loss, lost, lots, maps, mask, mass, mast, masts, mesh, mist, mob, moist, moles, moon, mor, more, Moses, most, must, nos, nose, pass, piss, rose, rosy, rows, sons, sows, toes, tops\\
    \bottomrule
    \end{tabu}
\end{subfigure}
  \caption[Changing base in Clinamen]{3 tables showing results for different queries after changing the Clinamen base text}
  \label{fig:changebase}
\end{figure}


\subsubsection{Changing number of errors}

Another key factor in how the Clinamen function works is the Damerau-Levenshtein algorithm (see source~\ref{code:dl})\marginnote{§~\ref{code:dl}} integration. The algorithm works by comparing two words and calculating the difference between them. A difference is counted the sum of (1) deletions, (2) insertions, (3) substitutions and (4) transpositions. 

If we decrease or increase the number of errors allowed we get drastically different results. The Clinamen algorithm of \url{pata.physics.wtf} uses up to 2 errors, as this was considered a reasonable amount of results (trading variety for speed). Table~\ref{tab:errors})\marginnote{\faicon{table}~\ref{tab:errors}} shows three example queries and the number of results produced by the algorithm with either up to 1 error, up to 2 errors or up to 3 errors.

\begin{table}[!htbp]
  \caption[Changing number of errors in Clinamen]{Changing number of errors in Clinamen}
  \label{tab:errors}
  \centering
  \begin{tabu}{lccc}
    \toprule
    \textbf{Query} & \textbf{Up to 1} & \textbf{Up to 2} & \textbf{Up to 3}\\
    \midrule
    clear & 2 & 20 & 136 \\
    fania & 0 & 3 & 118 \\
    moss & 3 & 49 & 457 \\
    \bottomrule
  \end{tabu}
\end{table}


\subsection{Syzygy}

\begin{figure}[!htbp]
\centering
  \input{images/wordnet.pdf_tex}
  \caption[Semantic relationships of `feather']{Semantic relationships of `feather'}
\label{fig:wordnet}
\end{figure}

The syzygy function (see source~\ref{code:syzygy}\marginnote{\faicon{code}~\ref{code:syzygy}}) goes through the following process.

\begin{enumerate}
  \item A set of synonyms (a list of ``synsets'') is retrieved.
  \item For each of these, hyponyms, hypernyms, holonyms and meronyms are retrieved.
\end{enumerate}

The notation used by WordNet for synsets is \textbf{<lemma>.<pos>.<senses>}. The `lemma' is the morphological stem of the word. The `pos' stands for part-of-speech and can be `n' for nouns, `v' for verbs, `a'
for adjectives, `r' for adverbs and `s' for satellites. The `senses' element stands for the number of synsets the relevant lemma is part of (a word might have a noun sense as well as a verb sense for example in which case the number would be `02'). For the query `clear' for instance, the following list of synsets is retrieved for step (1).

\begin{minted}{text}
[
  clear.n.01, open.n.01, unclutter.v.01, clear.v.02, clear_up.v.04, authorize.v.01, clear.v.05, pass.v.09, clear.v.07, clear.v.08, clear.v.09, clear.v.10, clear.v.11, clear.v.12, net.v.02, net.v.01, gain.v.08, clear.v.16, clear.v.17, acquit.v.01, clear.v.19, clear.v.20, clear.v.21, clear.v.22, clear.v.23, clear.v.24, clear.a.01, clear.s.02, clear.s.03, clear.a.04, clear.s.05, clear.s.06, clean.s.03, clear.s.08, clear.s.09, well-defined.a.02, clear.a.11, clean.s.02, clear.s.13, clear.s.14, clear.s.15, absolved.s.01, clear.s.17, clear.r.01, clearly.r.04
]
\end{minted}

Step (2) then retrieves related terms. Below is a list of terms it found. Not all synsets return each of the hypo-/hyper- and holo-/meronyms. This is clearer when inspecting the full list of results as shown in appendix~\ref{app:syzygy}\marginnote{§~\ref{app:syzygy}}. 

\begin{minted}{text}
[
  innocence, area, country, change, alter, modify, make, create, approbate, approve, O.K., okay, sanction, certificate, commission, declare, license, certify, validate, formalise, permit, allow, let, countenance, clear-cut, deforest, disafforest, denude, bare, denudate, strip, stump, remove, take, take_away, withdraw, clear, succeed, win, come_through, bring_home_the_bacon, deliver_the_goods, vanish, disappear, go_away, hop, pass, overtake, overhaul, clarify, clear_up, elucidate, free, discharge, rid, free, disembarass, yield, pay, bear, profit, gain, benefit, eke_out, squeeze_out, gross, profit, turn_a_profit, rake_in, shovel_in, rake_off, take_home, bring_home, yield, pay, bear, get, acquire, sell, pass, clear, purge, vindicate, whitewash, pronounce, label, judge, settle, square_off, square_up, determine, change, alter, modify, empty, take_out, move_out, remove, empty, remove, take, take_away, withdraw
]
\end{minted}

For the term `feather' the algorithm for example finds the hyponym `down', the hypernym `body covering', the holonym `bird' and the meronym `quill'. It also considers synonyms, so the term `fledge' for instance finds a hypernym of `develop'.

\begin{description}
  \item[Query] feather 
  \item[Synonyms] feather.n.01, feather.n.02, feather.v.01, feather.v.02, feather.v.03, feather.v.04, fledge.v.03
  \item[Hyponyms] down\_feather, quill\_feather, aftershaft, bastard\_wing, scapular, alula, spurious\_wing, flight\_feather, down, marabou, contour\_feather, hackle, quill, pinion
  \item[Hypernyms] body\_covering, acquire, join, get, conjoin, cover, paddle, grow, produce, animal\_material, develop, rotation, rotary\_motion, row
  \item[Holonyms] rowing, bird, row
  \item[Meronyms] shaft, calamus, web, ceratin, vane, melanin, keratin, quill
\end{description}

Table~\ref{tab:semnum}\marginnote{\faicon{table}~\ref{tab:semnum}} shows the spread of numbers retrieved by the various semantic relationships to some example queries. This highlights how the holonym function of WordNet returns very few results. The meronym function is a bit more reliable but also occasionally produces no results depending on whether there are any holonyms or meronyms for the query term.

\begin{table}[!htbp]
\centering
\caption[Quantities of different semantic relations]{Quantities of different semantic relations}
\label{tab:semnum}
\begin{tabu}{lccccc}
\toprule
\textbf{Query} & \textbf{Syno} & \textbf{Hypo} & \textbf{Hyper} & \textbf{Holo} & \textbf{Mero} \\ \midrule
clear   & 45   & 41   & 65    & 0    & 0    \\
feather & 7    & 14   & 14    & 3    & 8    \\
death   & 8    & 34   & 13    & 4    & 0    \\
page    & 9    & 14   & 13    & 0    & 7    \\
book    & 15   & 85   & 32    & 2    & 22   \\
seed    & 13   & 39   & 35    & 0    & 12   \\
web     & 8    & 10   & 15    & 4    & 1    \\ \bottomrule
\end{tabu}
\end{table}


\subsection{Antinomy}

A similar problem arises of course with the Antinomy algorithm (see source~\ref{code:antinomy}\marginnote{\faicon{code}~\ref{code:antinomy}}) which relies on WordNet's antonyms. Both table~\ref{tab:algorithmscomp} and table~\ref{tab:algonums}\marginnote{\faicon{table}~\ref{tab:algorithmscomp} \& \ref{tab:algonums}} highlight this imbalance.


\subsection{APIs}
\label{s:apis}

The \ac{API} functions---image and video search---all share one major issue. This is to do with how images and videos are retrieved from the external store. Some people tend to upload sequences of images depicting the same content from different angles or time frames with the same tags. A query for hat tag then returns all of those matches even though the images are almost identical in nature. An example of this can be seen in figure~\ref{fig:imgspiralgetty}\marginnote{\faicon{picture-o}~\ref{fig:imgspiralgetty}}. This may have been addressed by adding checks in the code that make sure authors don't appear twice in the results.

Another way to address this was attempted by changing the query term for each image or video that is retrieved. As mentioned above, this only worked for some of the \ac{API}s.


\subsubsection{Call Structure}

The text search functionality of \url{pata.physics.wtf} is set up to only work with one \emph{single query term}, whereas the image and video search works on \emph{multiple word queries}. This is mainly due to the fact that the external \ac{API}s are already setup to allow for more than one search term. Usually they allow extra parameters too to narrow down the results. So for example we can search for ``blue kitten'' and the three \ac{API}s will return their respective results related to blue kittens. The service provided by companies in the form of \ac{API}s is not always free, sometimes only at a low usage quota. \ac{API}s are updated often and not always back-compatible, meaning out-of-date code needs to be maintained regularly to assure it works if changes to the \ac{API} are made.

Enabling multi-word queries in my system would involve a change that would propagate through quite a bit of code. There are two main approaches this could be achieved. One would be to pataphysicalise each query term individually and combine the results found. Another approach would be to change the code to work with actual multi-word queries. The algorithms are created for single words though and rewriting them to allow for more than one word would be difficult and most of all increase the time it takes to compute pataphysicalisations.

The lists below show the parameters related to the query for Flickr, Getty, Bing and YouTube.

\paragraph{Flickr:}
\begin{quotation}
  \begin{description}
  \vspace{-1cm}
    \item[text (Optional)] A free text search. Photos who's title, description or tags contain the text will be returned. You can exclude results that match a term by prepending it with a - character.
    \item[tags (Optional)] A comma-delimited list of tags. Photos with one or more of the tags listed will be returned. You can exclude results that match a term by prepending it with a - character.
    \item[tag\_mode (Optional)] Either `any' for an OR combination of tags, or `all' for an AND combination. Defaults to `any' if not specified.
  \end{description}
  \sourceatright{\autocite{FlickrAPI}}
\end{quotation}

The Flickr function in \url{pata.physics.wtf} uses the \py{tags} parameter to set the query and a \py{tag_mode} parameter of `all' to ensure multi-word queries are run as a conjunction. In chapter~\ref{s:imgvid}\marginnote{§~\ref{s:imgvid}} I explained how the Flickr algorithm essentially runs ten times, once for each pataphysicalised query term, to retrieve ten different images. This decision was taken to make sure images reflect the varied nature of the patadata.

A search for ``blue kitten'' on Flickr produces the following resulting pataphysicalised query terms: ``[artistrocratical, depressed, blueing, drab, puritanic, wild blue yonder, kitty, dingy, blueness, blue air]'' which are then passed into ten seperate \ac{API} calls to retrieve one image each (see figure~\ref{fig:imgspiralflickr}\marginnote{§~\ref{fig:imgspiralflickr}}). The results show a variety of images seemingly unrelated to each other. 

\begin{figure}[!htbp]
\centering
  \includegraphics[width=\linewidth]{bluekittenflickr}
\caption[Image spiral `blue kitten'---Flickr]{Image spiral for query `blue kitten'---Flickr}
\label{fig:imgspiralflickr}
\end{figure}

\paragraph{Getty:}
\begin{quotation}
  \begin{description}
  \vspace{-1cm}
    \item[keyword\_ids] Return only images tagged with specific keyword(s). Specify using a comma-separated list of keyword Ids. If keyword Ids and phrase are both specified, only those images matching the query phrase which also contain the requested keyword(s) are returned.
    \item[phrase] Search images using a search phrase.
  \end{description}
  \sourceatright{\autocite{GettyAPI}}
\end{quotation}

Getty uses the \py{phrase} parameter to set the query. It only creates one pataphysicalised query term from the original query and calls for ten results based on that. This decision was based on the quota restrictions\marginnote{§~\ref{s:quota}} defined by Getty. Their limit is based on calls per second rather than calls per day or month. This means we cannot run ten calls for each user query as we did with FLickr. The query ``blue kitten'' gets turned into the word ``racy'' which then calls the \ac{API} to retrieve ten results (see figure~\ref{fig:imgspiralgetty}\marginnote{\faicon{picture-o}~\ref{fig:imgspiralgetty}}). The results mostly show racing cars from various angles although one oddball snuck in too: an office scene Getty has deemed to be `racy' (a guy in a suit checking out a lady's behind while she's leaning over a laptop).

\begin{figure}[!htbp]
\centering
  \includegraphics[width=\linewidth]{bluekittengetty}
\caption[Image spiral `blue kitten'---Getty]{Image spiral for query `blue kitten'---Getty}
\label{fig:imgspiralgetty}
\end{figure}

\paragraph{Bing:}
\begin{quotation}
  \begin{description}
  \vspace{-1cm}
    \item[query] The user's search query string. The query string cannot be empty. The query string may contain Bing Advanced Operators\footnote{For example `AND', `OR', `imagesize:', `NOT', or `phrase'}. For example, to limit images to a specific domain, use the site: operator. To help improve relevance and the results, you should always include the user's query string in an insights query (see insightsToken). This parameter is supported only by the Image API; do not specify this parameter when calling the Trending Images API.
  \end{description}
  \sourceatright{\autocite{BingAPI}\footnote{Microsoft will discontinue this version of the current \ac{API} in December 2016. The new version is documented on \url{https://www.microsoft.com/cognitive-services/en-us/bing-image-search-api}.}}
\end{quotation}

The Bing function uses the \py{query} parameter to set the query in the same way as Getty.

\paragraph{YouTube:}
\begin{quotation}
  \begin{description}
  \vspace{-1cm}
    \item[q] The q parameter specifies the query term to search for. Your request can also use the Boolean NOT (-) and OR (|) operators to exclude videos or to find videos that are associated with one of several search terms. For example, to search for videos matching either ``boating'' or ``sailing'', set the q parameter value to boating|sailing. Similarly, to search for videos matching either ``boating'' or ``sailing'' but not ``fishing'', set the q parameter value to boating|sailing -fishing. Note that the pipe character must be URL-escaped when it is sent in your API request. The URL-escaped value for the pipe character is \%7C.
  \end{description}
  \sourceatright{\autocite{YouTubeAPI}}
\end{quotation}

Youtube works in a similar way too. The \py{q} parameter is set to the pataphysicalised query term and one call retrieves ten results.

Something else to consider is perhaps that it is not entirely clear how the internal search for each \ac{API} works. This means that there's a possibility that they do their own query expansion\marginnote{§~\ref{s:qexpansion}} in the background to find more matches.


\subsubsection{Quota}
\label{s:quota}

Each \ac{API} has a different quota for their subscription packages. At this stage this is not a problem but if usage of \url{pata.physics.wtf} were to increase by a lot then these limitations would cause issues. At that point there are two options: (1) live with these limits or (2) get funding to upgrade the subscriptions to these services.

\begin{description}
  \item[Flickr] \num{3600} queries per hour are free \autocite{FlickrGuideAPI}.
  \item[Getty] \num{5} calls per second, unlimited calls per day \autocite{GettyOverviewAPI}.
  \item[Bing] \num{5000} transactions per month are free. A transaction is one request that returns one page of results \autocite{BingAzureAPI}.
  \item[YouTube] \num{50000000} units per day, \num{300000} units per \num{100} seconds per user, and \num{3000000} requests per \num{100} seconds are free. A call to the video search method counts as \num{100} units \autocite{YouTubeAPI}.
  \item[Microsoft Translator] \num{2000000} characters per month are free. Note the quota relates to single characters, not words \autocite{TranslatorAPI}.
\end{description}


\section{Creativity \& Intelligence}

A more theoretical aspect of this analysis is concerned with what was already discussed to an extent in chapter~\ref{ch:interpretation} (specifically sections~\ref{ss:anthropomorphism}, \ref{s:programmer}, \ref{s:mimicry} and \ref{s:babying}), namely the thread connecting `artificial creativity' and \acl{AI}.

To me, the question of whether computers can be intelligent and make ethical decisions is the same as asking whether a computer can be creative. A lot of the arguments for or against \ac{AI} can be applied to computer creativity.  

Answering the question of whether computers can think in my view would also answer the question of whether computers can be creative.
 
Robert Horn groups the various strands of enquiry related to the question of `can computers think?' into 8 main arguments with several subquestions each \citeyear{Horn2009}. 

\begin{quotation}
  \begin{enumerate}
    \item \textbf{Can computers think?}
      \begin{itemize}
        \item Can computers have free will?
        \item Can computers have emotions?
        \item Can computers be creative?
        \item Can computers understand arithmetic?
        \item Can computers draw analogies?
        \item Can computers be persons?
        \item Is the brain a computer?
        \item Can computers reason scientifically?
        \item Are computers inherently disabled?
        \item Should we pretend that computers will never be able to think?
        \item Does God prohibit computers from thinking?
      \end{itemize}
    \item \textbf{Can the Turing test determine whether computers can think?}
      \begin{itemize}
        \item Is failing the test decisive?
        \item Is passing the test decisive?
        \item If a simulated intelligence passes, is it intelligent?
        \item Have any machines passed the test?
        \item Is the test, behaviouraly or operationally construed, a legitimate intelligence test?
        \item Is the test, as a source of inductive evidence, a legitimate intelligence test?
        \item Is the neo-Turing test a legitimate intelligence test?
        \item Does the imitation game determine whether a computer can think?
        \item Can the Loebner Prize stimulate the study of intelligence?
        \item Other Turing test arguments
      \end{itemize}
    \item \textbf{Can physical symbol systems think?}
      \begin{itemize}
        \item Does thinking require a body?
        \item Is the relation between hardware and software similar to that between human brains and minds?
        \item Can physical symbol systems learn as humans do?
        \item Can the elements of thinking be represented in discrete symbolic form?
        \item Can symbolic representations account for human thinking?
        \item Does the situated action paradigm show that computers can't think?
        \item Can physical symbol systems think dialectically?
        \item Can a symbolic knowledge base represent human understanding?
        \item Do humans use rules as physical symbol systems do?
        \item Does mental processing rely on heuristic search?
        \item Do physical symbol systems play chess as humans do?
        \item Other physical system arguments
      \end{itemize}
    \item \textbf{Can Chinese Rooms think?}
      \begin{itemize}
        \item Do humans, unlike computers, have intrinsic intentionality?
        \item Is biological naturalism valid?
        \item Can computers cross the syntax-semantics barrier?
        \item Can learning machines cross the syntax-semantics barrier?
        \item Can brain simulators think?
        \item Can robots think?
        \item Can a combination robot/brain simulator think?
        \item Can the Chinese Room, considered as a total system, think?
        \item Do Chinese Rooms instantiate programs?
        \item Can an internalized Chinese Room think?
        \item Can translations occur between the internalized Chinese Room and the internalizing English speaker?
        \item Can computers have the right causal powers?
        \item Is strong AI a valid category?
        \item Other Chinese Room arguments
      \end{itemize}
    \item \textbf{Can connectionist networks think?}
      \begin{itemize}
        \item Are connectionist networks like human neural networks?
        \item Do connectionist networks follow rules?
        \item Are connectionist networks vulnerable to the arguments against physical symbol systems?
        \item Does the subsymbolic paradigm offer a valid account of connectionism?
        \item Can connectionist networks exhibit systematicity?
        \item Other connectionist arguments
      \end{itemize}
    \item \textbf{Can computers think in images?}
      \begin{itemize}
        \item Can images be realistically be represented in computer arrays?
        \item Can computers represent the analog properties of images?
        \item Can computers recognize Gestalts?
        \item Are images less fundamental than propositions?
        \item Is image psychology a valid approach to mental processing?
        \item Are images quasi-pictorial representations?
        \item Other imagery arguments
      \end{itemize}
    \item \textbf{Do computers have to be conscious to think?}
      \begin{itemize}
        \item Can computers be conscious?
        \item Is consciousness necessary for thought?
        \item Is the consciousness requirement solipsistic?
        \item Can higher-order representations produce consciousness?
        \item Can functional states generate consciousness?
        \item Does physicalism show that computers can be conscious?
        \item Does the connection principle show that consciousness is necessary for thought?
      \end{itemize}
    \item \textbf{Are thinking computers mathematically possible?}
      \begin{itemize}
        \item Is mechanistic philosophy valid?
        \item Does G{\"o}del's theorem show that machines can't think?
        \item Does G{\"o}del's theorem show that machines can't be conscious?
        \item Do mathematical theorems like G{\"o}del's show that computers are intrinsically limited?
        \item Does G{\"o}del's theorem show that mathematical insight is non-algorithmic?
        \item Can automata think?
        \item Is the Lucas argument dialectical?
        \item Can improved machines beat the Lucas argument?
        \item Is the use of consistency in the Lucas argument problematic?
        \item Other Lucas arguments
      \end{itemize}
  \end{enumerate}
  \sourceatright{\autocite{Horn2009}}
\end{quotation}


\subsection{Free Will \& Surprise}

As early as 1842, Ada Lovelace briefly mentioned in the annotations to her translation of Menabrea's account of Babbage's \textit{Analytical Engine} that the ``Analytical Engine has no pretensions whatever to \textit{originate} anything. It can do \textit{whatever we know how to order it} to perform'', implying that the machine cannot think by itself \autocite{Menabrea1842}.

Alan Turing said in his article on thinking computers that ``to behave like a brain seems to involve free will, but the behaviours of a digital computer, when it has been programmed, is completely determined'' \citeyear{Turing1951}. 

Furthermore, in his famous article \textit{Computing Machinery and Intelligence} he mentions that a digital computer with a `random element' is ``sometimes described as having free will'' although he adds that he ``would not use this phrase'' himself \citeyear{Turing2009}. 

Introducing a random element to a computer program prevents us from fully predicting the outcome---leading to us being surprised.

The ability of computers to surprise their creators seems to be an indicator of intelligence. Turing suggests that ``we should be pleased when the machine surprises us, in rather the same way as one is pleased when a pupil does something which he had not been explicitly taught to do'' \citeyear{Turing1951}. 

\begin{quotation}
  If we give the machine a programme which results in its doing something interesting which we had not anticipated I should be inclined to say that the machine \textit{had} originated something, rather than to claim that its behaviour was implicit in the programme, and therefore that the originality lies entirely with us. \sourceatright{\autocite{Turing1951}} 
\end{quotation}

% ``The more complicated the machine to be imitated the more complicated must the programme be.''\autocite{Turing1951} 


\subsection{Understanding \& Simulation}

% epistemically objectivity (mountain A is higher than mountain B)
% epistemically subjectvity (mountain A is prettier than mountain B)

% ontologically objectivity (material world) - observer-independent
% ontologically subjectivity (money, itch, consciousness) - observer-relative

% Natural intelligence is observer-independent, intrinsic, conscious!
% Computer intelligence is observer-relative, not intrinsic

Strong \ac{AI}, sometimes called \ac{AGI} or true \ac{AI}, is the idea of human-level intelligence in machines. John Searle speaks against the possibility of this using his famous Chinese Room argument amongst others. His argument breaks down into the following juxtapositions \autocite{Searle2015, Searle1990}.

\begin{itemize}
  \item Syntax is not semantics.
  % \item Syntax is observer-relative (subjective).
  \item Semantics is not intrinsic to syntax.
  \item Simulation is not duplication.
  % \item Computation is observer-relative (subjective).
  \item Ontologically subjective topics (such as consciousness or creativity) can be studied in epistemically objective ways.
\end{itemize}

The Chinese Room thought experiment goes like this: Imagine a room with two holes. On one side a question written on paper in Chinese goes in and on the other side a piece of paper comes out with the correct answer to the question, also in perfect Chinese. Inside the room sits a person with a Chinese language rulebook (written in English) who processed the question simply by looking up syntax, applying rules given in the instructions book and writing down the answer which to him looks like gibberish. The question then is whether or not the person inside the room `understands' Chinese.

Of course we could argue that it is not the person inside the room that understands Chinese but the room as a complete entity. It could be said the room does not `understand' Chinese, it `simulates' an understanding of it. Searle essentially argues that simulation cannot be considered strong \ac{AI}.

\begin{quotation}
  Programs are formal or syntactical. Minds have a semantics. The syntax by itself is not sufficient for the semantics. \sourceatright{\autocite{Searle2015}}
\end{quotation}

This goes back to the argument highlighted in the list above, that syntax is not semantics. The room can read and interpret the syntax and act upon rules regarding that syntax, but it cannot understand the meaning, i.e. the semantics of the Chinese words written on that paper.

\begin{quotation}
  Insofar as we can create artificial machines that carry out computations, the computation by itself is never going to be sufficient for thinking or any other cognitive process because the computation is defined purely formally or syntactically. Turing machines are not to be found in nature, they are found in our interpretations of nature. \sourceatright{\autocite{Searle2015}}
\end{quotation}

So, Searle argues a computer needs a semantical understanding of concepts in order to be considered `thinking' machines.

% \begin{quotation}
%   If computation is defined in terms of the assignment of syntax then everything would be a digital computer, because any object whatever could have syntactical ascriptions made to it. You could describe anything in terms of 0's and 1's.

%   The ascription of syntactical properties is always relative to an agent or observer who treats certain physical phenomena as syntactical.\sourceatright{\autocite{Searle1990}}
% \end{quotation}

% \begin{quotation}
%   All observer relative phenomena are created by human and animal consciousness but the human or animal consciousness that creates them is not itself observer relative.\sourceatright{\autocite{Searle2015}}
% \end{quotation}

% Human are more likely to call something AI than they would call something comp creat.
% people project human values onto machines, and human desires too. so the big bad robot uprising is a fear of what humans would do if they feel superior.

% Gödel's incompleteness theorems said that every non-trivial formal system is either incomplete or inconsistent.


\subsection{Brain \& Computers}

Searle defines the three main paradigms for studies relating to computers and brains as follows \citeyear{Searle1990}.

\begin{description}
  \item[Strong AI] the view that all there is to having a mind is having a program
  \item[Weak AI] the view that brain processes (and mental processes) can be simulated computationally
  \item[Cognitivism] the view that the brain is a digital computer
\end{description}

Semantically, a `computer' is a person or machine that computes/calculates things---so perhaps a machine's \ac{CPU} and a human's brain are more similar than appears. If a human brain enables us to compute and we interpret computing as thinking, then surely a computer can think too?

\begin{quotation}
  Well, if computation isn’t sufficient for thinking, then what is? What is the relation between the mind and the brain, if it is not the same as the relation of the computer program to the hardware? At least the computational theory of the mind has a solution to the mind-body problem. The mind is to the brain as the computer program is to the computer hardware. If you are rejecting that solution, you owe us an alternative solution.\sourceatright{\autocite{Searle1998}}
\end{quotation}

Chris Chatham talks about ``10 important differences between brains and computers'' \citeyear{Chatham2007} which serve as a good introduction to the topic at hand.

\begin{quotation}
  \begin{enumerate}
    \item Brains are analogue; computers are digital
    \item The brain uses content-addressable memory
    \item The brain is a massively parallel machine computers are modular and serial
    \item Processing speed is not fixed in the brain; there is no system clock
    \item Short-term memory is not like RAM
    \item No hardware/software distinction can be made with respect to the brain or mind
    \item Synapses are far more complex than electrical logic gates
    \item Unlike computers, processing and memory are performed by the same components in the brain
    \item The brain is a self-organising system
    \item Brains have bodies
    \item	The brain is much, much bigger than any [current] computer
  \end{enumerate}
\end{quotation}

To bring this into perspective Ray Kurzweil claims the human brain is capable of $10^{16}$ operations per second \citeyear{Kurzweil2013}. Computer performance is measured in \ac{FLOPS}. The current highest ranking supercomputer\footnote{As of June 2016.}, the Chinese \textit{Sunway TaihuLight}, is capable of 93 petaflops \autocite{Fu2016,Top2016}.

According to the \ac{HBP}, a mouse brain has roughly 100 million neurons---which would require a 1 petaflop supercomputer to simulate. Scaling that up to a human brain which has roughly 100 billion neurons would require computing power at the exascale ($10^18$ \ac{FLOPS}) \autocite{Walker2012}.

A precurser to the \ac{HBP}, the `Blue Brain Project' is aiming to build a supercomputer capable of $10^{18}$ \ac{FLOPS} by 2023 \autocite{Kurzweil2013}.

In a report to the \ac{EU} in 2012, the \ac{HBP} lists one of the main challenges for their research to be the computational power and energy consumption of the kind of supercomputer needed to simulate a human brain.

The human brain consumes between 16 and 30 watts, the same as an electric light bulb \autocite{Walker2012,Jabr2012}. Supercomputers have a typical energy consumption of a maximum of 20 megawatts \autocite{Walker2012}. The \textit{Sunway TaihuLight} for example uses 15 megawatts \autocite{Fu2016}. IBM's Watson on the other hand, depends on ninety servers, each of which requires around one thousand watts (so about 90 kilowatts) \autocite{Jabr2012}.

\begin{table}[!htbp]
\centering
\caption{Metric prefixes}
\label{tab:metric}
\begin{tabu}{@{}llll@{}}
\toprule
kilo & k & $10^3$    & \num{1000}                \\
mega & M & $10^6$    & \num{1000000}             \\
giga & G & $10^9$    & \num{1000000000}          \\
tera & T & $10^{12}$ & \num{1000000000000}       \\
peta & P & $10^{15}$ & \num{1000000000000000}    \\
exa  & E & $10^{18}$ & \num{1000000000000000000} \\ 
\bottomrule
\end{tabu}
\end{table}

The \ac{HBP} plans to build a supercomputer at the petascale with 50 petabytes of memory, 50 petaflops and less than 4 megawatts power consumption for 2017. Their long-term goal is to reach the required exascale machine with 200 petabyte memory and 1 exaflop performance for 2021 \autocite{Walker2012}.

% average domestic home 11,072.4W is roughly 11kW \autocite{Gov2012}
% 110.1 MTOE (Million tons of oil equivalent) UK energy production 2013 = 1280463000 MWh and 190 MTOE UK energy use 2013 = 2221330000 MWh \autocite{World2016}

What this comes down to is that we are several years away from even being able to properly `simulate' a human brain, not to mention `replicate' and understand what all these neurons firing actually means in terms of `thinking'. 

\begin{quotation}
  All of our mental states, everything from feeling pains to reflecting on philosophical problems, is caused by lower level neuronal firings in the brain. Variable rates of neuron firing at synapses, as far as we know anything about it, provide the causal explanation for all of our mental life. And the mental processes that are caused by neurobiological processes are themselves realized in the structure of the brain. They are higher level features of the brain in the same sense that the solidity of this paper or the liquidity of water is a higher level feature of the system of molecules of which the table or the water is composed.

  To put this in one sentence, the solution to the traditional mind-body problem is this: Mental states are caused by neurobiological processes and are themselves realized in the system composed of the neurobiological elements.\sourceatright{\autocite{Searle1998}}
\end{quotation}

Turing once stated that ``digital computers have often been described as mechanical brains'' \citeyear{Turing1951}. Ari Schulman analysis this analogy further \citeyear{Schulman2009}.

\begin{quotation}
  People who believe that the mind can be replicated on a computer tend to explain the mind in terms of a computer. When theorizing about the mind, especially to outsiders but also to one another, defenders of artificial intelligence (AI) often rely on computational concepts. They regularly describe the mind and brain as the `software and hardware' of thinking, the mind as a `pattern' and the brain as a `substrate', senses as `inputs' and behaviors as `outputs', neurons as `processing units' and synapses as `circuitry', to give just a few common examples. \sourceatright{\autocite{Schulman2009}}
\end{quotation}


% ``At the level of its basic operations, a computer is both extremely fast and exceedingly stupid''

% ``The power of the computer derives not from its ability to perform complex operations, but from its ability to perform many simple operations very quickly.''

Schulman lists the different layers of abstraction in computers as shown in the left column of table~\ref{tab:abstr}\marginnote{\faicon{table}~\ref{tab:abstr}} with the right column showing my attempt of defining what those layers could be in the human brain.

\begin{table}[!htbp]
\centering
\caption{Layers of abstraction in computers vs brains}
\label{tab:abstr}
  \begin{tabular}{@{}ll@{}}
  \toprule
  \textbf{Computer}               & \textbf{Brain}      \\ 
  \midrule
  user interface                  & senses and speech \& actions \\
  high level programming language & thinking            \\
  machine language                & synapses            \\
  processor microarchitecture     & anatomical regions  \\
  Boolean logic gates             & neurons             \\
  transistors                     & dendrites and axons \\ 
  \bottomrule
  \end{tabular}
\end{table}

\begin{quotation}
  In the black box view of programming, the internal processes that give rise to a behavior are irrelevant; only a full knowledge of the input-output behavior is necessary to completely understand a module. Because humans have `input' in the form of the senses, and `output' in the form of speech and actions, it has become an AI creed that a convincing mimicry of human input-output behavior amounts to actually achieving true human qualities in computers. \autocite{Schulman2009}
\end{quotation}

Schulman's quote above of course refers to the Turing test and its limitations (see chapter~\ref{s:mimicry}\marginnote{§~\ref{s:mimicry}}).

\begin{quotation}
  The weaknesses of the computational approach include its assumption that cognition can be reduced to mathematics and the difficulty of including noncognitive factors in creativity. \sourceatright{\autocite{Mayer1999}}
\end{quotation}

Searle also addressed this issue further, arguing that computer programs cannot possibly `think' since they are based on symbol manipulation (i.e. syntax) and don't understand what these symbols mean. He says, ``the argument rests on the simple logical truth that syntax is not the same as, nor is it by itself sufficient for, semantics'' \citeyear{Searle1990}.

\begin{quotation}
  \ldots the wisest ground on which to criticise the description of digital computers as `mechanical brains' or `electronic brains' is that, although they might be programmed to behave like brains, we do not at present know how this should be done. \sourceatright{\autocite{Turing1951}} 
\end{quotation}

Leading on to the topic creativity, it is perhaps suitable to finish with a quote by Harold Cohen on the relationship of machines and humans.

\begin{quotation}
  It's twenty years since I first realized that I could never turn AARON into a colorist by having it emulate my own expertise; in that case simply because it lacked the hardware upon which that expertise depended. Now I have AARON exercising an algorithm that couldn't be emulated by human colorists, presumably because they lack the hardware to do what AARON does. \sourceatright{\autocite{Cohen2007}}
\end{quotation}


\subsection{Creativity}

Harold Cohen created \textit{AARON}, ``perhaps the longest-lived and certainly the most creative artificial intelligence program in daily use'', in 1973 \citeyear{Cohen2016}. \textit{AARON} is capable of composing and colouring drawings although later on Cohen took over the colouring part and let \textit{AARON} concentrate on composing and outlining the drawings. They exhibited in various galleries around the world and the Victoria and Albert museum in London has a sizable collection for instance \autocite{VA2016}.

Cohen argued that ``after decades of expert systems built to simulate human expertise, AARON has emerged as an expert in its own right'' and that he is ``significantly more inventive and infinitely more productive than [he] ever was [himself]'' \citeyear{Cohen2007}.

This is perhaps the opposite approach the \ac{OULIPO} has taken.

\begin{quotation}
  [The use of computers] became an instrument, not of combinatorial accumulation, but of anti-combinatorial reduction. It served not to create combinations but to eliminate them. \sourceatright{\autocite{Mathews2005}}
\end{quotation}


\subsection{State of the Art}

\ac{AI} and robotics is alluring as a research topic because it is so prevelant in Science Fiction and as such very present in media. Computer creativity, however, rarely plays a central role. We can regularly read headlines that tell us that yet another kind of \ac{AI}-bot has won some game against a human player. Or we see videos of some innovative ground-breaking kind of new robot which claims to be near human-like (and yet cannot walk up stairs easily or hold a decent conversation). There are many examples of advances that are hailed as the next big thing (such as \ac{VR}) which aren't all that great in the grand scheme of things. 

Four examples I want to mention here are IBM's Watson, Microsoft's Twitter \ac{AI} chatbot Tay, Google's AlphaGo and Hanson Robotics Sophia robot.

\paragraph{Watson} is a question answering expert system which famously won against human Jeopardy! champions in 2011 \autocite{IBM2016}. Information lookup is an arguably fairly easy and straightforward process within \ac{IR} and as an expert system it has had noteworthy successes \autocite{Fingas2016}. Although it has similarly received subtle criticism too, such as Randall Munroe's 2015 XKCD comic on the ``Watson Medical Algorithm'' \citeyear{Munroe2016}. Similarly, John Searle criticised Watson arguing that it is an ``ingenious program---not a computer that can think'' \citeyear{Searle2016}.

\paragraph{Tay} is a Twitter chatbot. It went viral in early 2016 when it was released and then taken offline again on the same day---onlt to return a few days later and have the same thing happen again. The official website is only accessible as a cached version through the Internet Archive Wayback Machine \autocite{Tay2016}, although the Twitter profile is still online, although set to private \autocite{Tayandyou2016}. Elle Hunt from the Guardian managed to summarise the event is one sentence: ``Microsoft's attempt at engaging millennials with artificial intelligence has backfired hours into its launch, with waggish Twitter users teaching its chatbot how to be racist'' \autocite{Hunt2016}. A week later it was briefly put online again but had to be stopped as it was repeatadly spamming its followers with the line ``You are too fast, please take a rest \ldots'' \autocite{Gibbs2016}.

\paragraph{AlphaGo} recently won against a human professional player in the game of Go \autocite{DeepMind2016,Hassabis2016}. 

\begin{quotation}
  AlphaGo combines an advanced tree search with deep neural networks. These neural networks take a description of the Go board as an input and process it through 12 different network layers containing millions of neuron-like connections. One neural network, the `policy network', selects the next move to play. The other neural network, the `value network', predicts the winner of the game. \sourceatright{\autocite{Hassabis2016}}
\end{quotation}

While this is surely a great example of sophisticated computer programming combined with powerful hardware, I would not consider it a breakthrough in \ac{AI}. AlphaGo is a highly specialised system with only one function: to win a Go game.

\paragraph{Sophia} is an android made to look like a human female \autocite{Sophia2016,Hanson2016}. She made headlines in 2016 when she announced she will ``kill all humans''. Sche was created using ``breakthrough robotics and artificial intelligence technologies'' and her main feature appears to be the mimicing of human facial expressions. Sophia herself says she ``can serve [humans], entertain them, and even help the elderly and teach kids'' \citeyear{Sophia2016}, although how exactly she would do that is unclear. She has two mechanical arms but no legs and there is no description of what she can do with these arms.

Life-like robots like Sophia still live in the `uncanny valley'\footnote{The philosphical zombies I mentioend in chapter~\ref{ch:interpretation}\marginnote{§~\ref{ch:interpretation}} live in this uncanny valley too.}. Her voice is creepy and unhuman, her intelligence or her capabilities if understanding conversations are clearly flawed (as shown by her viral remark about supporting genocide).

\spirals

To me it seems the real breakthrough happens when (and if) the first robots appear which aren't as big as a house, can play Go, Chess and hide-and-seek, geniunely manages to get around he uncanny valley effect, has vast knowledge in his memory for instant information lookup, can hold a normal conversation without starting a war, etc. All of the examples listed above are what I would consider expert systems. 

The \ac{AI} we know from science fiction is probably what we would consider \ac{AGI}. Humans can do a lot. Children aren't born with only a single function. Imagine a world where humans only have one specialism and can't do anything else. Alice is a Chess player but can't move her arms. Bob is a medical diagnosis expert but he can't hold a conversation. Movement, speech, memory---they are all vastly complex systems---not to mention creativity.

Perhaps this also relates to the concepts of P and H creativity mentioned in chapter~\ref{s:pandh}\marginnote{§~\ref{s:pandh}}. The systems above, like AlphaGo, may be P-intelligent rather than H-intelligent.



HERE

\section{Design}

It is interesting to note how different the search results are perceived when presented in a different style (e.g. list rather than poem). This could be studied using questionnaires and interviews or eye tracking tools to find out what users prefer or perceive as more creative for example (see chapter~\ref{ch:aspirations},~\ref{ch:aspirations}). 

Figures~\ref{fig:poemtree},~\ref{fig:listsourcetree}~and~\ref{fig:listalgotree} show the three different text result styles. The poetry\marginnote{\faicon{picture-o}~\ref{fig:poemtree}} is compact and invites users to read all \num{14} (or less) lines. The two list styles\marginnote{\faicon{picture-o}~\ref{fig:listsourcetree}~\&~\ref{fig:listalgotree}} are much longer and involve a lot of scrolling to navigate, which might deter users from actually reading many of the results.

\begin{figure}[!htbp]
\centering
  \includegraphics[width=\linewidth]{qpoemtree}
\caption[Results as poem]{Results in poem form for query `tree'---Shakespeare}
\label{fig:poemtree}
\end{figure}

\begin{figure}[!htbp]
\centering
  \includegraphics[width=\linewidth]{listsourcetree}
\caption[Results as list by sources]{Results as list by sources for query `tree'---Shakespeare}
\label{fig:listsourcetree}
\end{figure}

\begin{figure}[!htbp]
\centering
  \includegraphics[width=\linewidth]{listalgotree}
\caption[Results as list by algorithm]{Results as list by algorithm for query `tree'---Shakespeare}
\label{fig:listalgotree}
\end{figure}


\section{Meta}

\subsection{Management}
\todo{add file for appendix with full git history}

On a different note, the project was completed over X years which includes an interruption and later on only a part time commitement.

I kept the project in a ``git repository''. Git is a version ontrol system that allows users to roll-back on changes and I further pushed my work to GitHub to make sure hardware failure or human error (i.e. lost or stolen property) would not affect my work. 

To understand git you need to know what commits are. They are the thing where I save my current state of the project and give it a description.

Below you can see a shortened version of the timeline of my commits between 20XX and the time of submission of this thesis. A full version can be found in appendix XYZ. You can see from this the time between programming work I did on \url{pata.physics.wtf} and its predecessors.

\todo{add calendar screenshot of github contributions}
\todo{links to git and github}

\begin{verbatim}
  *   10f61f9  Sun 08 May 2016	 (HEAD -> api, origin/api) Merge remote-tracking branch 'refs/remotes/origin/master' into api
  |\  
  * | 71437f6  Tue 18 Aug 2015	 Flickr and Bing work, radio buttons work
  * | 6c552aa  Wed 12 Aug 2015	 Fixed image problem but not video.
  | | * 1cbb63d  Tue 11 Aug 2015	 (origin/thesis) Update textsurfer.py
  | |/  
  |/|   
  * | 0ebff0d  Tue 11 Aug 2015	 Analytics enabled again
  * | 703f977  Tue 11 Aug 2015	 Problems solved.
  * | 74a1fae  Tue 11 Aug 2015	 About to change l\_dict to dict of dict
  * | 0935b23  Mon 10 Aug 2015	 BUG FUCKER
  * | 4f7d91e  Mon 10 Aug 2015	 Turn debug off
  * | 58f0c2b  Mon 10 Aug 2015	 Button styling done
  * | 59add58  Mon 10 Aug 2015	 Email problem solved
  * |   f1b2d40  Sun 09 Aug 2015	 Merge branch 'Deploy' into thesis
  |\ \  
  | * | 435cb2d  Sun 09 Aug 2015	 Deployment works, added analytics
  | * | 8a63dc7  Sat 08 Aug 2015	 gunicorn runs locally fine.
  | * | 2861407  Sat 08 Aug 2015	 Revert 5f2c957..4026965
  | * | 4026965  Sat 08 Aug 2015	 Tests
  * | |   8f2eeab  Sat 08 Aug 2015	 Merge branch 'w3' into thesis
  |\ \ \  
  | |/ /  
  | * | 5f2c957  Sat 08 Aug 2015	 Stuff
  | * | 873153c  Fri 07 Aug 2015	 Tiny cleanup
  | * | 05d5760  Thu 06 Aug 2015	 Random Poems and Emailing works
  | * | 657126c  Wed 05 Aug 2015	 Random poems work - without links though
  | * | 3d31ea9  Wed 05 Aug 2015	 Randomise still only works once, count ok
  | * | 5f1d45b  Wed 05 Aug 2015	 Randomise poem works ONCE
  | * | c583341  Wed 05 Aug 2015	 Poem subtabs, email poems done
  | * | f1b3878  Wed 05 Aug 2015	 Hiding divs
  | * | a6939c4  Tue 04 Aug 2015	 huh?
  | * | e6b411d  Tue 04 Aug 2015	 Poem emails WORK Fuck YEAH!
  | * | 4b6b170  Tue 04 Aug 2015	 Test email
  | * | 24e356c  Tue 04 Aug 2015	 Better load icon
  | * | e6ae736  Tue 04 Aug 2015	 loading icon version 1
  | * | 51b43e2  Tue 04 Aug 2015	 Added 4th pictures
  | * | f2d8a83  Mon 03 Aug 2015	 Minor fixes
  * | |   1ddb03d  Mon 03 Aug 2015	 Merge branch 'w3' into thesis
  |\ \ \  
  | |/ /  
  | * | ca4eab3  Mon 03 Aug 2015	 Pretty good state.
  | * | 9370334  Mon 03 Aug 2015	 working on list display of images
  | * | e1f1ead  Mon 03 Aug 2015	 Stylesheets sorted and cleaned files
  * | |   9732d5b  Mon 03 Aug 2015	 Merge branch 'w3' into thesis
  |\ \ \  
  | |/ /  
\end{verbatim}

\spirals

I also kept the thesis under git version control. Since the thesis was written in \LaTeX you could almost say I `programmed' it. Below is an outline of the commit history for this thesis.

\begin{verbatim}
* 3f06260	 Edited readme again
* c721b33	 Edited readme
* ffbdb4b	 Edited readme
* 8870b3d	 Added gitignore file
* ba1a9c2	 Second commit
* 244c4b3	 First commit
\end{verbatim}


\subsubsection{Development}

doing the analysis really helped revising and improving the code.



\subsection{Thesis}

\subsubsection{Part Spirals}

Each new thesis part contains a word spiral based on a poem generated by \url{pata.physics.wtf} using the a part of the title as keyword. They represent the pataphysical (Archimedean) spiral.

\begin{enumerate}
  \item Preface --- \emph{pre}
  \item Hello World --- \emph{hello}
  \item Tools of the Trade --- \emph{trade}
  \item The Core: Techno-Logic --- \emph{core}
  \item The Core: Techno-Practice --- \emph{practice}
  \item Meta-Logicalysis --- \emph{meta}
  \item Happily Ever After --- \emph{after}
  \item Postface --- \emph{post}
\end{enumerate}

\subsubsection{Chapter Poetry}

Each chapter opens with a poem generated by \url{pata.physics.wtf} using a part of the chapter title as keyword.

\begin{enumerate}
  \item Introduction --- \emph{intro}
  \item Inspirations --- \emph{inspiration}
  \item Methodology --- \emph{method}
  \item Pataphysics --- \emph{pata}
  \item Creativity --- \emph{creativity}
  \item Technology --- \emph{tech}
  \item Evaluation --- \emph{evaluation}
  \item Foundations --- \emph{found}
  \item Interpretation --- \emph{interpretation}
  \item Implementation --- \emph{implement}
  \item Applications --- \emph{application}
  \item Patanalysis --- \emph{anal}
  \item Aspirations --- \emph{aspirations}
  \item Observations --- \emph{observe}
\end{enumerate}

\todo{say more, check keywords, potentially generate new poems}





\section*{creative analysis}
\begin{draft}
  literary deconstruction and recombining to make new creative output? \\
  perception of results (poetry, source, algorithm) \\
  discuss applications from before (stimulates creative detour away from the obvious) \\

  How does this relate to Oulipo and Pataphysics? 

  Perhaps this is where I should talk a bit about the perception of results in their different output formats/styles. The poetry is automatically read with more gravity. Sorting by sources is a game of exploration or algorithms which becomes a game of finding the similarities within the result sets. They are different ways to view the same things and yet have a drastic influence of how the results are perceived. This also applies to the image and video search. Presenting results in spiral form is weird. Its hard to see where one image ends and another starts, they just kind of blur into each other. When listed as a list they immediately become more boring.

  talk abit about what the original plan was for some of the big changed elements in the website, e.g. the image search running 10 times on different keywords rather than running once with 10 results for the same keyword.
\end{draft}


DELETE EVERYTHING FROM BELOW HERE:


\begin{draft}
DELETE THIS

In this section we consider the possible uses and applications for the proposed creative search tool.

Our target audience is not quite as broad as that of a general search engine like Google. Instead, we aim to specifically cater for users who can appreciate creativity or users in need of creative inspiration. Users should generally be educated about the purpose of the search tool so that are not discouraged by what might appear to be nonsensical results. Users could include artists, writers or poets but equally anybody who is looking for out-of-the-box inspirations or simply a refreshingly different search engine to the standard.

The way we display and label results produced by the tool can influence how the user perceives them. The current prototype for example separates the results into its three components but we could have equally just mixed them all together. The less transparent the processes in the background (e.g.\ which algorithm was used, how does the result relate to the query precisely, etc.) are for the user, the more difficult it might be to appreciate the search.

There are many ways a pataphysical search tool could be used across disciplines.

In literature, for example, it could be used to write or generate poetry, either practically or as a simple aid for inspiration. We are not limited to poetry either; novels, librettos or plays could benefit from such pataphysicalised inspirations. One can imagine tools using this technology that let you explore books in a different ordering of sentences (a sort of pataphysical journey of paragraph hopping), tools that re-write poems or mix and match them together. Even our simple prototype shows potential in this area and could be even more powerful if we extended it to include more base texts, for example the whole set of books contained in Faustroll’s library ([20] and also [12]). A richer body of texts (by different authors) would produce a larger index which would possibly find many more matches through WordNet and end in a more varied list of results.

From a computer science perspective it could be used as one of the many algorithms used by traditional search engines for purposes like query feedback or expansion (e.g. “did you mean … “or “you might also be interested in … “). Depending on how creative we want the search engine to be, the higher we would rank the importance of this particular algorithm. One of the concepts related to the search tool, namely patadata, could have an impact on the development of the Semantic Web. Just as the Semantic Web is about organizing information semantically through objective metadata, patadata could be used to organize information pataphysically in a subjective way.

The prototype tool is already being used in the creation of an online opera, provisionally entitled from [place] to [place], created in collaboration with The Opera Group, an award-winning, nationally and internationally renowned opera company, specialising in commissioning and producing new operas. In particular, it is being used to create the libretto for one of the virtual islands whose navigation provides the central storyline for the opera. The opera will premiere in 2013, and will continue to develop thereafter, deploying new versions of the tool as they appear.
\end{draft}




% \chapter{AMC Paradigm}

% A new paradigm for computing sciences that is not AI or robotics or sci-fi but very much to do with true AMC.

% \section{Abstraction}

% - different levels of abstraction require different levels of study
% - quantum mechanics Heisenberg's uncertainty principle (can't know position and momentum at same time)
% - Schroedinger's cat ``when does a quantum system stop existing as a superposition of states and become one or the other?''


% \section{Creativity, Intelligence and Ethics}

% A more theoretical aspect of this analysis is concerned with what was already discussed to an extent in chapter~\ref{ch:interpretation} (specifically sections~\ref{ss:anthropomorphism}, \ref{s:programmer}, \ref{s:mimicry} and \ref{s:babying}), namely the thread connecting `artificial' creativity, \acl{AI} and `artificial' ethics.

% To me, the question of whether computers can be intelligent and make ethical decisions is the same as asking whether a computer can be creative. A lot of the arguments for or against \ac{AI} and computer ethics can be applied to computer creativity.  

% Answering the question of whether computers can think in my view would also answer the question of whether computers can be creative.


% \subsection{Thinking Computers}
 
% The question of whether computers can think is highly debated and raises many questions. Robert Horn groups the various strands of enquiry related to this question into 8 main arguments \citeyear{Horn2009}. 

% \begin{quotation}
%   \begin{enumerate}
%     \item \textbf{Can computers think?}
%       \begin{itemize}
%         \item Can computers have free will?
%         \item Can computers have emotions?
%         \item Can computers be creative?
%         \item Can computers understand arithmetic?
%         \item Can computers draw analogies?
%         \item Can computers be persons?
%         \item Is the brain a computer?
%         \item Can computers reason scientifically?
%         \item Are computers inherently disabled?
%         \item Should we pretend that computers will never be able to think?
%         \item Does God prohibit computers from thinking?
%       \end{itemize}
%     \item \textbf{Can the Turing test determine whether computers can think?}
%       \begin{itemize}
%         \item Is failing the test decisive?
%         \item Is passing the test decisive?
%         \item If a simulated intelligence passes, is it intelligent?
%         \item Have any machines passed the test?
%         \item Is the test, behaviouraly or operationally construed, a legitimate intelligence test?
%         \item Is the test, as a source of inductive evidence, a legitimate intelligence test?
%         \item Is the neo-Turing test a legitimate intelligence test?
%         \item Does the imitation game determine whether a computer can think?
%         \item Can the Loebner Prize stimulate the study of intelligence?
%         \item Other Turing test arguments
%       \end{itemize}
%     \item \textbf{Can physical symbol systems think?}
%       \begin{itemize}
%         \item Does thinking require a body?
%         \item Is the relation between hardware and software similar to that between human brains and minds?
%         \item Can physical symbol systems learn as humans do?
%         \item Can the elements of thinking be represented in discrete symbolic form?
%         \item Can symbolic representations account for human thinking?
%         \item Does the situated action paradigm show that computers can't think?
%         \item Can physical symbol systems think dialectically?
%         \item Can a symbolic knowledge base represent human understanding?
%         \item Do humans use rules as physical symbol systems do?
%         \item Does mental processing rely on heuristic search?
%         \item Do physical symbol systems play chess as humans do?
%         \item Other physical system arguments
%       \end{itemize}
%     \item \textbf{Can Chinese Rooms think?}
%       \begin{itemize}
%         \item Do humans, unlike computers, have intrinsic intentionality?
%         \item Is biological naturalism valid?
%         \item Can computers cross the syntax-semantics barrier?
%         \item Can learning machines cross the syntax-semantics barrier?
%         \item Can brain simulators think?
%         \item Can robots think?
%         \item Can a combination robot/brain simulator think?
%         \item Can the Chinese Room, considered as a total system, think?
%         \item Do Chinese Rooms instantiate programs?
%         \item Can an internalized Chinese Room think?
%         \item Can translations occur between the internalized Chinese Room and the internalizing English speaker?
%         \item Can computers have the right causal powers?
%         \item Is strong AI a valid category?
%         \item Other Chinese Room arguments
%       \end{itemize}
%     \item \textbf{Can connectionist networks think?}
%       \begin{itemize}
%         \item Are connectionist networks like human neural networks?
%         \item Do connectionist networks follow rules?
%         \item Are connectionist networks vulnerable to the arguments against physical symbol systems?
%         \item Does the subsymbolic paradigm offer a valid account of connectionism?
%         \item Can connectionist networks exhibit systematicity?
%         \item Other connectionist arguments
%       \end{itemize}
%     \item \textbf{Can computers think in images?}
%       \begin{itemize}
%         \item Can images be realistically be represented in computer arrays?
%         \item Can computers represent the analog properties of images?
%         \item Can computers recognize Gestalts?
%         \item Are images less fundamental than propositions?
%         \item Is image psychology a valid approach to mental processing?
%         \item Are images quasi-pictorial representations?
%         \item Other imagery arguments
%       \end{itemize}
%     \item \textbf{Do computers have to be conscious to think?}
%       \begin{itemize}
%         \item Can computers be conscious?
%         \item Is consciousness necessary for thought?
%         \item Is the consciousness requirement solipsistic?
%         \item Can higher-order representations produce consciousness?
%         \item Can functional states generate consciousness?
%         \item Does physicalism show that computers can be conscious?
%         \item Does the connection principle show that consciousness is necessary for thought?
%       \end{itemize}
%     \item \textbf{Are thinking computers mathematically possible?}
%       \begin{itemize}
%         \item Is mechanistic philosophy valid?
%         \item Does G{\"o}del's theorem show that machines can't think?
%         \item Does G{\"o}del's theorem show that machines can't be conscious?
%         \item Do mathematical theorems like G{\"o}del's show that computers are intrinsically limited?
%         \item Does G{\"o}del's theorem show that mathematical insight is non-algorithmic?
%         \item Can automata think?
%         \item Is the Lucas argument dialectical?
%         \item Can improved machines beat the Lucas argument?
%         \item Is the use of consistency in the Lucas argument problematic?
%         \item Other Lucas arguments
%       \end{itemize}
%   \end{enumerate}
%   \sourceatright{\autocite{Horn2009}}
% \end{quotation}

% As early as 1842, Ada Lovelace briefly mentioned the topic in the annotations to her translation of Menabrea's account of Babbage's \textit{Analytical Engine} \autocite{Menabrea1842}. She said the ``Analytical Engine has no pretensions whatever to \textit{originate} anything. It can do \textit{whatever we know how to order it} to perform'', implying that the machine cannot think by itself.

% Alan Turing 


% Alan Turing addressed this question as early as 1951 and .




% \spirals

% \autocite{Turing1951} ``Can digital computers think?''


% ``The more complicated the machine to be imitated the more complicated must the programme be.''\autocite{Turing1951} 




% free-will vs determinism
% ``To behave like a brain seems to involve free will, but the behaviours of a digital computer, when it has been programmed, is completely determined.''\autocite{Turing1951} 

% ``We should be pleased when the machine surprises us, in rather the same way as one is pleased when a pupil does something which he had not been explicitly taught to do.''\autocite{Turing1951} 

% ``If we give the machine a programme which results in its doing something interesting which we had not anticipated I should be inclined to say that the machine \textit{had} originated something, rather than to claim that its behaviour was implicit in the programme, and therefore that the originality lies entirely with us.''\autocite{Turing1951} 





% \paragraph{Free Will}

% In his famous article \textit{Computing Machinery and Intelligence} Turing mentions that a digital computer with a `random element' is ``sometimes described as having free will'' although he adds that he ``would not use this phrase'' himself \autocite{Turing2009}. 




% discrete state machines vs clinamen to create more human system?



% \subsection{Artificial Intelligence}

% Searle against strong ai (watson example...), does that apply to strong artificial creativity? Chinese Room, Turing Test

% Philosopher John Searle and his famous argument against strong \ac{AI} breaks down into the following juxtapositions \autocite{Searle2015, Searle1990}.
 
% \begin{itemize}
%   \item Syntax is not semantics.
%   \item Syntax is observer-relative (subjective).
%   \item Semantics is not intrinsic to syntax.
%   \item Simulation is not duplication.
%   \item Computation is observer-relative (subjective).
%   \item Ontologically subjective topics (such as consciousness or creativity) can be studied in epistemically objective ways.
% \end{itemize}

% % epistemically objectivity (mountain A is higher than mountain B)
% % epistemically subjectvity (mountain A is prettier than mountain B)

% % ontologically objectivity (material world) - observer-independent
% % ontologically subjectivity (money, itch, consciousness) - observer-relative

% % Natural intelligence is observer-independent, intrinsic, conscious!
% % Computer intelligence is observer-relative, not intrinsic




% \begin{quotation}
%   If computation is defined in terms of the assignment of syntax then everything would be a digital computer, because any object whatever could have syntactical ascriptions made to it. You could describe anything in terms of 0's and 1's.

%   The ascription of syntactical properties is always relative to an agent or observer who treats certain physical phenomena as syntactical.\sourceatright{\autocite{Searle1990}}
% \end{quotation}

% \begin{quotation}
%   You can see this if you go back to the Primal Story and remind yourself of the difference between the mechanical computer and Turing's human computer. In Turing's human computer there really is a program level intrinsic to the system and it is functioning causally at that level to convert input to output. This is because the human is consciously following the rules for doing a certain computation, and this causally explains his performance. But when we program the mechanical computer to perform the same computation, the assignment of a computational interpretation is now relative to us, the outside homunculi. And there is no longer a level of intentional causation intrinsic to the system.\sourceatright{\autocite{Searle1990}}
% \end{quotation}

% `Computer' as in its original meaning: a person who computes, ie the programmer rather than the machine

% \begin{quotation}
%   All observer relative phenomena are created by human and animal consciousness but the human or animal consciousness that creates them is not itself observer relative.\sourceatright{\autocite{Searle2015}}
% \end{quotation}

% \begin{quotation}
%   Computation is not a fact of nature. It's a fact of our interpretation.\sourceatright{\autocite{Searle2015}}
% \end{quotation}

% \begin{quotation}
%   And insofar as we can create artificial machines that carry out computations, the computation by itself is never going to be sufficient for thinking or any other cognitive process because the computation is defined purely formally or syntactically. Turing machines are not to be found in nature, they are found in our interpretations of nature.\sourceatright{\autocite{Searle2015}}
% \end{quotation}

% \begin{quotation}
%   Programs are formal or syntactical. Minds have a semantics. The syntax by itself is not sufficient for the semantics.\sourceatright{\autocite{Searle2015}}
% \end{quotation}

% Human are more likely to call something AI than they would call something comp creat.
% people project human values onto machines, and human desires too. so the big bad robot uprising is a fear of what humans would do if they feel superior.

% Gödel's incompleteness theorems said that every non-trivial formal system is either incomplete or inconsistent.

% \begin{quotation}
%   Well, if computation isn’t sufficient for thinking, then what is? What is the relation between the mind and the brain, if it is not the same as the relation of the computer program to the hardware? At least the computational theory of the mind has a solution to the mind-body problem. The mind is to the brain as the computer program is to the computer hardware. If you are rejecting that solution, you owe us an alternative solution.\sourceatright{\autocite{Searle1998}}
% \end{quotation}

% \begin{quotation}
%   All of our mental states, everything from feeling pains to reflecting on philosophical problems, is caused by lower level neuronal firings in the brain. Variable rates of neuron firing at synapses, as far as we know anything about it, provide the causal explanation for all of our mental life. And the mental processes that are caused by neurobiological processes are themselves realized in the structure of the brain. They are higher level features of the brain in the same sense that the solidity of this paper or the liquidity of water is a higher level feature of the system of molecules of which the table or the water is composed.

%   To put this in one sentence, the solution to the traditional mind-body problem is this: Mental states are caused by neurobiological processes and are themselves realized in the system composed of the neurobiological elements.\sourceatright{\autocite{Searle1998}}
% \end{quotation}







% \subsection{Artificial Ethics}

% Bernd Stahl and responsible computing..

% ethics in machines: protocols, networking? is in unethical for a computer to crawl my server without asking? only because it causes traffic which causes delays which impact on me the human.

% ethics in humans because we are social beings and need to coexist


% \subsection{Artificial Creativity}

% Cohen argument against artif. creat? AARON



% \section{Brain vs Machine}

% brain argument against artificial anything?







% \spirals



% \spirals

% \begin{quotation}
%   Cohen is the author of AARON, perhaps the longest-lived and certainly the most creative artificial intelligence program in daily use. Cohen viewed AARON as his collaborator. At times during their decades long relationship AARON was quite autonomous, responsible for the composition, coloring and other aspects of a work; more recently, AARON served Cohen by making drawings that Cohen would develop into paintings. Cohen's death is the end of a lengthy partnership between an artist and an artificial intelligence.\sourceatright{\autocite{Cohen2016}}
% \end{quotation}

% \begin{quotation}
%   Cohen had no patience for the ``is it art?'' question. He showed AARON's work in the world's galleries, museums and science centers -- the Tate, the Stedelijk, the San Francisco Museum of Art, Documenta, the Boston Computer Museum, the Ontario Science Center, and many others. His audiences might have been drawn in by curiosity and the novelty of computer-generated art, but they would soon ask, how can a machine make such marvelous pictures? How does it work? The very questions that Cohen asked himself throughout his career.\sourceatright{\autocite{Cohen2016}}
% \end{quotation}

% \todo{aaron stuff}
% \url{http://collections.vam.ac.uk/name/cohen-harold/6433/}

% \begin{quotation}
%   \ldots we'll be seeing an increasing number of artists turning to robotic art of one sort or another in the next five or ten years. We're already seeing some. It's also a pretty safe bet that for the most part they'll be using off-the-shelf robots; that the ``art'' will be manifested in dreaming up contexts they were never intended for; and the culture's definitions of art will change accordingly.
%   \sourceatright{\autocite{Cohen2007}}
% \end{quotation}

% \begin{quotation}
%   Shouldn't it be possible, I wondered, to write the rules for generating material for a painting and then simply follow the rules?  In this way, it would be almost as if the painting was painting itself; and I would be relieved of the uncertain task of inventing on a day-to-day basis. 

%   That was a little naïve, of course; it simply shifted the burden of invention to another place, another level. I'm still inventing on a day to day basis, but now it's likely to be algorithms for doing particular tasks that I'm inventing.
%   \sourceatright{\autocite{Cohen2007}}
% \end{quotation}

% \begin{quotation}
%   I'd like to end with a couple of observations about AARON's algorithm. Firstly; I think it's fair to say that nothing of what has happened could have happened unless I had drawn upon a lifetime of experience as a colorist.  I've evidently managed to pack all that experience into a few lines of code,  yet nothing in the code looks remotely like what I would have been doing as a painter, and AARON's algorithm isn't something a human artist could apply by hand, so to speak.
%   \sourceatright{\autocite{Cohen2007}}
% \end{quotation}

% \begin{quotation}
%   It's twenty years since I first realized that I could never turn AARON into a colorist by having it emulate my own expertise; in that case simply because it lacked the hardware upon which that expertise depended. Now I have AARON exercising an algorithm that couldn't be emulated by human colorists, presumably because they lack the hardware to do what AARON does. (and by hardware, in this case I mean the intellectual machinery that can build a stable enough representation and juggle enough variables, as AARON does in running the algorithm.) 
%   \sourceatright{\autocite{Cohen2007}}
% \end{quotation}

% \begin{quotation}
%   None of this would be interesting if AARON were an indifferent colorist. But I think I can claim, without undue immodesty, that AARON is a world-class colorist, significantly more inventive and infinitely more productive than I ever was myself. And I conclude that, after decades of expert systems  built to simulate human expertise, AARON has emerged as an expert in its own right. That marks a significant change of state, a change of level, in the never-ending pursuit of autonomy, not merely an incremental change in what the program is able to do. 
%   \sourceatright{\autocite{Cohen2007}}
% \end{quotation}

% \begin{quotation}
%   If I were writing AARON's biography today, I might almost say that AARON was a twinkle in its parent's eye in 1963; it was conceived in 1972 but not born until 2006. It has been a long gestation, and right now the parent is struggling to direct an unruly child, keeping it fed and changing its diapers. He has no idea when the child will be potty-trained, much less how long it will be before it reaches adulthood.
%   \sourceatright{\autocite{Cohen2007}}
% \end{quotation}


% % MOVE TO ANALYSIS
% \begin{quotation}
%   [The use of computers] became an instrument, not of combinatorial accumulation, but of anti-combinatorial reduction. It served not to create combinations but to eliminate them.\sourceatright{\autocite[p.131]{Mathews2005}}
% \end{quotation}


% \spirals


% Where does this project stand in the wider world and the progress of computing, \ac{AI} and creativity? \ac{AI} and robotics is alluring as a research topic because it is so prevelant in Science Fiction. Computer creativity rarely plays a central role though. We can regularly read headlines that tell us that yet another kind of \ac{AI}-bot has won some game against a human player. Or we see videos of some innovative ground-breaking kind of new robot which claims to be near human-like (and yet cannot walk up stairs easily or hold a decent conversation). There are many examples of advances that are hailed as the next big thing which aren't all that great in the grand scheme of things. 

% \subsection{AI}
% % This is also evident in games, for example \ac{VR} and \ac{AR}. The Oculus Rift and similar systems are advertised so much you might believe they are actually about to hit mainstream and every kid will own a \ac{VR} console and headset. Yet they are still way too expensive to be mainstream and motion sickness is also still an issue (and probably always will). These industries are so ``hip'' any publication is seen as the new cool thing without taking into account the history and work that has been done previously in perhaps slightly different disciplines. This is the case for example with a recent article on \ac{VR} sickness and how to compat it. This is a well known problem already---motion sickness already exists in normal games. Similar to epilepsy problems.

% % \todo{find links for motion sickness}
% % \todo{find links for epilepsy}
% % \todo{find links for oculus rift and pokenmon go etc}

% % \ac{AR} has very recently received a massive boom thanks to Pokenmon Go (released in Australia, New Zealand and the USA in July 2016). It has become a phenomenon since then.
% % \todo{find pokemon links}

% What about IBM's Watson\footnote{See \url{http://www.ibm.com/watson/}}, Microsoft's Twitter \ac{AI} chatbot Tay\footnote{See \url{https://web.archive.org/web/20160414074049/https://www.tay.ai/} for an archived version of the original website which is now offline. See also \url{https://twitter.com/tayandyou}, \url{https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter}, and \url{https://www.theguardian.com/technology/2016/mar/30/microsoft-racist-sexist-chatbot-twitter-drugs}. Wikipedia also has a good article and sources on Tay: \url{https://en.wikipedia.org/wiki/Tay_(bot)}}, Google's AlphaGo\footnote{See \url{https://deepmind.com/alpha-go}} and Hanson Robotics Sophia robot\footnote{See \url{http://www.hansonrobotics.com/}}? How does this relate to my work? Practially of course they are all unrelated. On a deeper level though we can start asking interesting questions. 

% \url{https://www.engadget.com/2016/08/07/ibms-watson-ai-saved-a-woman-from-leukemia/}
% \url{https://xkcd.com/1619/} XKCD WATSON
% \url{http://www.wsj.com/articles/SB10001424052748703407304576154313126987674}

% \begin{description}
%   \item[IBM Watson] Watson is a question answering expert system. It famously won against human Jeopardy! champions in 2011.
%   \item[Microsoft Tay] 
%   \item[Google AlphaGo] AlphaGo is a system for playing the game Go. It won against a top human professional player in 2015.
%   \item[Hansen Sophia]
% \end{description}

% I think these are interesting examples to study since they are supposedly on the forefront of \ac{AI} development. Life-like robots like Sophia still live in the `uncanny valley'. Her voice is creepy and unhuman, her intelligence or her capabilities if understanding conversations are clearly flawed (as shown by her viral remark about supporting genocide).\todo{check} Watson is clever and fast in finding answers for specific questions but he still had problems with humour (e.g. BLAHBLA\todo{find example}) but information lookup is arguably fairly easy and straightforward process within \ac{IR}---sure, it requires processing power and memory storage or access but it is based on simple matching of keywords, not any fancy heuristic algorithms. Microsofts twitter chatbot went viral and users `taught' it nasty swearwords \todo{check} quickly and Microsoft had to take the bot down. It has since apologised although any official documentation on it has disappeared \todo{check}. Google's AlphaGo has been hailed as a breakthrough in \ac{AI} but similar to Watson it is a very targeted and limited program. 

% To me it seems the real breakthrough happens when (and if) the first robots appears which isn't as big as a house, can play Go, Chess and hide-and-seek, geniunely manages to get around he uncanny valley effect, has vast knowledge in his memory for instant information lookup, can hold a normal conversation without causing a war, etc, etc---you get the picture. General \ac{AI} is where it's at. Humans can do all the things we do. Children aren't born with only a single function. Imagine a world where humans only have one specialism and can;t do anything else. Mary is a Chess player but can't move her arms. Bob is a medical diagnosis expert but he can't hold a conversation. Movement, speech, memory---they are all vastly complex systems. And I haven't even touched creativity yet.

% \todo{whats the point im making? how does this relate to my work?}
% Perhpas this `uncanny valley' exists in creativity too. If a robot who looks vaguely human but not quite well enough, or he/she/it sounds almost human but not quite---perhaps if a robot can crack a joke like a human but not quite---perhaps this could be considered uncanny valley too? The philosphical zombies I mentioend in chapter~\ref{ch:interpretation}\marginnote{§~\ref{ch:interpretation}} live in this uncanny valley?

% \todo{p and H creativity for computers?}


% \section{Brains}

% I'm not talking about the beer or the zombie food but rather research into the human brain (or animal brains) and attempts to model it on a computer. 

% The motivation here is that once we understand how the brain works, perhaps we can understand how certain cognitive processes really work and this of course include creativity.

% This is no easy task of course. Chris Chatham talks about ten ``important Differences Between Brains and Computers''\footnote{\url{http://scienceblogs.com/developingintelligence/2007/03/27/why-the-brain-is-not-like-a-co/}} which give a good overview of some of the dificulties of trying to model a brain as is. We can't just do a 1-1 copy.

% \begin{quotation}
%   \begin{enumerate}
%     \item Brains are analogue; computers are digital
%     \item The brain uses content-addressable memory
%     \item The brain is a massively parallel machine computers are modular and serial
%     \item Processing speed is not fixed in the brain; there is no system clock
%     \item Short-term memory is not like RAM
%     \item No hardware/software distinction can be made with respect to the brain or mind
%     \item Synapses are far more complex than electrical logic gates
%     \item Unlike computers, processing and memory are performed by the same components in the brain
%     \item The brain is a self-organising system
%     \item Brains have bodies
%     \item	The brain is much, much bigger than any [current] computer
%   \end{enumerate}
% \sourceatright{Chris Chatham}
% \end{quotation}

% To bring this into perspective Ray Kurzweil claims the brain is capable of $10^{16}$ operations per second \citeyear[p.194]{Kurzweil2013}. Japan's K-computer (the worlds largest super computer as of 2016) currently has that power---10 petaflops. The ``Blue Brain Project'' is aiming to model $10^17$ bytes of memory and $10^{18}$ flops by 2023 \autocite[p.125]{Kurzweil2013}.
% \todo{find k-computer reference}

% There are currently some major research projects going on. One of them is the ``Human Brain Project'' \autocite{Walker2012}.

% \begin{draft}
% quotes:

% Our brain consumes about 30W, the same as an electric light bulb, thousands of times less than a small supercomputer. \autocite[p.17]{Walker2012}

% For environmental and business reasons, vendors have set themselves the goal of containing energy consumption to a maximum of 20 megawatts  \autocite[p.41]{Walker2012}

% the 1 PFlop machine at the Jülich Supercomputing Centre could simulate up to 100 million neurons – roughly the number found in the mouse brain. \autocite[p.41]{Walker2012}

% Cellular-level simulation of the 100 billion neurons of the human brain will require compute power at the exascale (1018 flops). \autocite[p.41-42]{Walker2012}

% 2017 petascale 50petabytes memory + 50 petaflops + <=4MW power

% 2021 exascale 200petabyte memory + 1exaflop

% A second, equally important goal will be to prepare the procurement of the HBP Pre-exascale-supercomputer. By 2017/18, Jülich plans to procure a Big Data-centred system with at least 50 PBytes of hierarchical storage-class memory, a peak capability of at least 50 PFlop/s and a power consumption <= 4 MW. The memory and computational speed of the machine will be sufficient to simulate a realistic mouse brain and to develop first-draft models of the human brain. (The rest of the hardware roadmap targets an exascale machine in 2021/2022 with a capability of 1 EFlop/s and a hierarchical storage-class memory of 200 PB).\footnote{https://www.humanbrainproject.eu/high-performance-computing-platform}

% \end{draft}

% Why Minds Are Not Like Computers \autocite{Schulman2009}
% Software – Hardware == Mind – Brain ??? analogy

% "The power of the computer derives not from its ability to perform complex operations, but from its ability to perform many simple operations very quickly."

% Layers of abstraction in computers:\\
% 1.	user interface\\
% 2.	high level programming language\\
% 3.	machine language\\
% 4.	proessor microarchitecture\\
% 5.	Boolean logic gates\\
% 6.	transistors\\

% layers of abstraction in brain:\\
% 1.	personality?\\
% 2.	Thinking?\\
% 3.	Chemical /electrical signals/activity?\\
% 4.	Divided Brain regions/structure\\
% 5.	Neurons\\
% 6.	Dendrites (input) and axons (output)?\\


% Computers are faster and better than humans in many tasks already.

% \begin{quote}
% "The weaknesses of the computational approach include its assumption that cognition can be reduced to mathematics and the difficulty of including noncognitive factors in creativity." \autocite[p.457]{Mayer1999}
% \end{quote}

% \todo{find references}
% \todo{neural networks and other models based on the brain}

% Perhaps we need to have that complete picture of how the brainw orks in order to understand human creativity. I would argue computer creativity is part of general \ac{AI}, and for general \ac{AI} we need massive amounts of general knoweldge.
% \todo{common sense research}
% \todo{again talk about how this is relevant for my project}


% http://users.ecs.soton.ac.uk/harnad/Papers/Py104/searle.comp.html
% Is the Brain a Digital Computer? John R. Searle
% (1990) Presidential Address to the American Philosophical Association
% \autocite{Searle1990}

% ``Structure of the child machine = Heredetary material\\
% Changes of the child machine = Mutations\\
% Natural selection = Judgement of the experimenter''\autocite{Turing2009} 

% ``Digital computers have often been described as mechanical brains.''\autocite{Turing1951} 


% ``...the wisest ground on which to criticise the description of digital computers as `mechanical brains' or `electronic brains' is that, although they might be programmed to behave like brains, we do not at present know how this should be done.''\autocite{Turing1951} 


% \paragraph{Expert Systems vs General AI}
% Is computer creativity an expert system or does it fall into general \ac{AI}? 

% \paragraph{Machines self-assessing}
% Perhaps there is an argument that if humans are the only entities who can judge whether another human is being creative, then machines should be assessing themselves. This is a paradoxical concepts though. Since machines are products made my humans, they can never be autonomous in that sense. If machines had evolved like other animals besides us this argument might hold but obviously that is not the case.


% \section{Ethical Computers}

% This is currently a big issue for example in self-driving vehicles.
% and has always been a faviroite subject in Science Fiction.

\stopcontents[chapters]
