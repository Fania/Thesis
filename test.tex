%
\documentclass[11pt]{thesis} % draft

\title{Algorithmic Meta-Creativity}
\author{Fania Raczinski}
\date{March 2015}


\begin{document}


% \chapter{AMC Paradigm}

% A new paradigm for computing sciences that is not AI or robotics or sci-fi but very much to do with true AMC.


% \section{Abstraction}

% To me, the question of whether computers can be intelligent and make ethical decisions includes asking whether a computer can be creative. A lot of the arguments for or against \ac{AI} can be applied to computer creativity.  

% - different levels of abstraction require different levels of study
% - quantum mechanics Heisenberg's uncertainty principle (can't know position and momentum at same time)
% - Schroedinger's cat ``when does a quantum system stop existing as a superposition of states and become one or the other?''



\section{Creativity \& Intelligence}

A more theoretical aspect of this analysis is concerned with what was already discussed to an extent in chapter~\ref{ch:interpretation} (specifically sections~\ref{ss:anthropomorphism}, \ref{s:programmer}, \ref{s:mimicry} and \ref{s:babying}), namely the thread connecting `artificial creativity' and \acl{AI}.

To me, the question of whether computers can be intelligent and make ethical decisions is the same as asking whether a computer can be creative. A lot of the arguments for or against \ac{AI} can be applied to computer creativity.  

Answering the question of whether computers can think in my view would also answer the question of whether computers can be creative.


\subsection{Thinking Computers}
 
Robert Horn groups the various strands of enquiry related to the question of `can computers think?' into 8 main arguments with several subquestions each \citeyear{Horn2009}. 

\begin{quotation}
  \begin{enumerate}
    \item \textbf{Can computers think?}
      \begin{itemize}
        \item Can computers have free will?
        \item Can computers have emotions?
        \item Can computers be creative?
        \item Can computers understand arithmetic?
        \item Can computers draw analogies?
        \item Can computers be persons?
        \item Is the brain a computer?
        \item Can computers reason scientifically?
        \item Are computers inherently disabled?
        \item Should we pretend that computers will never be able to think?
        \item Does God prohibit computers from thinking?
      \end{itemize}
    \item \textbf{Can the Turing test determine whether computers can think?}
      \begin{itemize}
        \item Is failing the test decisive?
        \item Is passing the test decisive?
        \item If a simulated intelligence passes, is it intelligent?
        \item Have any machines passed the test?
        \item Is the test, behaviouraly or operationally construed, a legitimate intelligence test?
        \item Is the test, as a source of inductive evidence, a legitimate intelligence test?
        \item Is the neo-Turing test a legitimate intelligence test?
        \item Does the imitation game determine whether a computer can think?
        \item Can the Loebner Prize stimulate the study of intelligence?
        \item Other Turing test arguments
      \end{itemize}
    \item \textbf{Can physical symbol systems think?}
      \begin{itemize}
        \item Does thinking require a body?
        \item Is the relation between hardware and software similar to that between human brains and minds?
        \item Can physical symbol systems learn as humans do?
        \item Can the elements of thinking be represented in discrete symbolic form?
        \item Can symbolic representations account for human thinking?
        \item Does the situated action paradigm show that computers can't think?
        \item Can physical symbol systems think dialectically?
        \item Can a symbolic knowledge base represent human understanding?
        \item Do humans use rules as physical symbol systems do?
        \item Does mental processing rely on heuristic search?
        \item Do physical symbol systems play chess as humans do?
        \item Other physical system arguments
      \end{itemize}
    \item \textbf{Can Chinese Rooms think?}
      \begin{itemize}
        \item Do humans, unlike computers, have intrinsic intentionality?
        \item Is biological naturalism valid?
        \item Can computers cross the syntax-semantics barrier?
        \item Can learning machines cross the syntax-semantics barrier?
        \item Can brain simulators think?
        \item Can robots think?
        \item Can a combination robot/brain simulator think?
        \item Can the Chinese Room, considered as a total system, think?
        \item Do Chinese Rooms instantiate programs?
        \item Can an internalized Chinese Room think?
        \item Can translations occur between the internalized Chinese Room and the internalizing English speaker?
        \item Can computers have the right causal powers?
        \item Is strong AI a valid category?
        \item Other Chinese Room arguments
      \end{itemize}
    \item \textbf{Can connectionist networks think?}
      \begin{itemize}
        \item Are connectionist networks like human neural networks?
        \item Do connectionist networks follow rules?
        \item Are connectionist networks vulnerable to the arguments against physical symbol systems?
        \item Does the subsymbolic paradigm offer a valid account of connectionism?
        \item Can connectionist networks exhibit systematicity?
        \item Other connectionist arguments
      \end{itemize}
    \item \textbf{Can computers think in images?}
      \begin{itemize}
        \item Can images be realistically be represented in computer arrays?
        \item Can computers represent the analog properties of images?
        \item Can computers recognize Gestalts?
        \item Are images less fundamental than propositions?
        \item Is image psychology a valid approach to mental processing?
        \item Are images quasi-pictorial representations?
        \item Other imagery arguments
      \end{itemize}
    \item \textbf{Do computers have to be conscious to think?}
      \begin{itemize}
        \item Can computers be conscious?
        \item Is consciousness necessary for thought?
        \item Is the consciousness requirement solipsistic?
        \item Can higher-order representations produce consciousness?
        \item Can functional states generate consciousness?
        \item Does physicalism show that computers can be conscious?
        \item Does the connection principle show that consciousness is necessary for thought?
      \end{itemize}
    \item \textbf{Are thinking computers mathematically possible?}
      \begin{itemize}
        \item Is mechanistic philosophy valid?
        \item Does G{\"o}del's theorem show that machines can't think?
        \item Does G{\"o}del's theorem show that machines can't be conscious?
        \item Do mathematical theorems like G{\"o}del's show that computers are intrinsically limited?
        \item Does G{\"o}del's theorem show that mathematical insight is non-algorithmic?
        \item Can automata think?
        \item Is the Lucas argument dialectical?
        \item Can improved machines beat the Lucas argument?
        \item Is the use of consistency in the Lucas argument problematic?
        \item Other Lucas arguments
      \end{itemize}
  \end{enumerate}
  \sourceatright{\autocite{Horn2009}}
\end{quotation}


\subsubsection{Free Will \& Surprise}

As early as 1842, Ada Lovelace briefly mentioned in the annotations to her translation of Menabrea's account of Babbage's \textit{Analytical Engine} that the ``Analytical Engine has no pretensions whatever to \textit{originate} anything. It can do \textit{whatever we know how to order it} to perform'', implying that the machine cannot think by itself \autocite{Menabrea1842}.

Alan Turing said in his article on thinking computers that ``to behave like a brain seems to involve free will, but the behaviours of a digital computer, when it has been programmed, is completely determined'' \citeyear{Turing1951}. 

Furthermore, in his famous article \textit{Computing Machinery and Intelligence} he mentions that a digital computer with a `random element' is ``sometimes described as having free will'' although he adds that he ``would not use this phrase'' himself \citeyear{Turing2009}. 

Introducing a random element to a computer program prevents us from fully predicting the outcome---leading to us being surprised.

The ability of computers to surprise their creators seems to be an indicator of intelligence. Turing suggests that ``we should be pleased when the machine surprises us, in rather the same way as one is pleased when a pupil does something which he had not been explicitly taught to do'' \citeyear{Turing1951}. 

\begin{quotation}
  If we give the machine a programme which results in its doing something interesting which we had not anticipated I should be inclined to say that the machine \textit{had} originated something, rather than to claim that its behaviour was implicit in the programme, and therefore that the originality lies entirely with us. \sourceatright{\autocite{Turing1951}} 
\end{quotation}

% ``The more complicated the machine to be imitated the more complicated must the programme be.''\autocite{Turing1951} 


\subsubsection{Understanding \& Simulation}

% epistemically objectivity (mountain A is higher than mountain B)
% epistemically subjectvity (mountain A is prettier than mountain B)

% ontologically objectivity (material world) - observer-independent
% ontologically subjectivity (money, itch, consciousness) - observer-relative

% Natural intelligence is observer-independent, intrinsic, conscious!
% Computer intelligence is observer-relative, not intrinsic

Strong \ac{AI}, sometimes called \ac{AGI} or true \ac{AI}, is the idea of human-level intelligence in machines. John Searle speaks against the possibility of this using his famous Chinese Room argument amongst others. His argument breaks down into the following juxtapositions \autocite{Searle2015, Searle1990}.

\begin{itemize}
  \item Syntax is not semantics.
  \item Syntax is observer-relative (subjective).
  \item Semantics is not intrinsic to syntax.
  \item Simulation is not duplication.
  \item Computation is observer-relative (subjective).
  \item Ontologically subjective topics (such as consciousness or creativity) can be studied in epistemically objective ways.
\end{itemize}

The Chinese Room thought experiment goes like this: Imagine a room with two holes. On one side a question written on paper in Chinese goes in and on the other side a piece of paper comes out with the correct answer to the question, also in perfect Chinese. Inside the room sits a person with a Chinese language rulebook (written in English) who processed the question simply by looking up syntax, applying rules given in the instructions book and writing down the answer which to him looks like gibberish. The question then is whether or not the person inside the room `understands' Chinese.

Of course we could argue that it is not the person inside the room that understands Chinese but the room as a complete entity. It could be said the room does not `understand' Chinese, it `simulates' an understanding of it. Searle essentially argues that simulation cannot be considered strong \ac{AI}.

\begin{quotation}
  Programs are formal or syntactical. Minds have a semantics. The syntax by itself is not sufficient for the semantics. \sourceatright{\autocite{Searle2015}}
\end{quotation}

This goes back to the argument highlighted in the list above, that syntax is not semantics. The room can read and interpret the syntax and act upon rules regarding that syntax, but it cannot understand the meaning, i.e. the semantics of the Chinese words written on that paper.

\begin{quotation}
  Insofar as we can create artificial machines that carry out computations, the computation by itself is never going to be sufficient for thinking or any other cognitive process because the computation is defined purely formally or syntactically. Turing machines are not to be found in nature, they are found in our interpretations of nature. \sourceatright{\autocite{Searle2015}}
\end{quotation}

So, Searle argues a computer needs a semantical understanding of concepts in order to be considered `thinking' machines.

% \begin{quotation}
%   If computation is defined in terms of the assignment of syntax then everything would be a digital computer, because any object whatever could have syntactical ascriptions made to it. You could describe anything in terms of 0's and 1's.

%   The ascription of syntactical properties is always relative to an agent or observer who treats certain physical phenomena as syntactical.\sourceatright{\autocite{Searle1990}}
% \end{quotation}

% \begin{quotation}
%   All observer relative phenomena are created by human and animal consciousness but the human or animal consciousness that creates them is not itself observer relative.\sourceatright{\autocite{Searle2015}}
% \end{quotation}

% Human are more likely to call something AI than they would call something comp creat.
% people project human values onto machines, and human desires too. so the big bad robot uprising is a fear of what humans would do if they feel superior.

% Gödel's incompleteness theorems said that every non-trivial formal system is either incomplete or inconsistent.


\subsubsection{Brain \& CPU}

Semantically, a `computer' is a person or machine that computes/calculates things---so perhaps a machine's \ac{CPU} and a human's brain are more similar than appears. If a human brain enables us to compute and we interpret computing as thinking, then surely a computer can think too?

\begin{quotation}
  Well, if computation isn’t sufficient for thinking, then what is? What is the relation between the mind and the brain, if it is not the same as the relation of the computer program to the hardware? At least the computational theory of the mind has a solution to the mind-body problem. The mind is to the brain as the computer program is to the computer hardware. If you are rejecting that solution, you owe us an alternative solution.\sourceatright{\autocite{Searle1998}}
\end{quotation}

Chris Chatham talks about ``10 important differences between brains and computers'' \citeyear{Chatham2007} which serve as a good introduction to the topic at hand.

\begin{quotation}
  \begin{enumerate}
    \item Brains are analogue; computers are digital
    \item The brain uses content-addressable memory
    \item The brain is a massively parallel machine computers are modular and serial
    \item Processing speed is not fixed in the brain; there is no system clock
    \item Short-term memory is not like RAM
    \item No hardware/software distinction can be made with respect to the brain or mind
    \item Synapses are far more complex than electrical logic gates
    \item Unlike computers, processing and memory are performed by the same components in the brain
    \item The brain is a self-organising system
    \item Brains have bodies
    \item	The brain is much, much bigger than any [current] computer
  \end{enumerate}
\end{quotation}

To bring this into perspective Ray Kurzweil claims the brain is capable of $10^{16}$ operations per second \citeyear{Kurzweil2013}. Japan's K-computer (the worlds largest super computer as of 2016) currently has that power---10 petaflops. The ``Blue Brain Project'' is aiming to model $10^17$ bytes of memory and $10^{18}$ flops by 2023 \autocite{Kurzweil2013}.

The \textit{\ac{HBP}} is a major \ac{EU} funded research project to try and understand the human brain \autocite{Walker2012}.

In a report to the \ac{EU} in 2012, the \ac{HBP} lists one of the main challenges for their research to be the computational power and energy consumption of the kind of supercomputer needed to simulate a human brain.

\begin{itemize}
  \item The human brain consumes about 30W, the same as an electric light bulb.
  \item Supercomputers have a typical energy consumption of a maximum of 20 megawatts\footnote{20MW is \num{20000000}W.}
  \item A mouse brain has roughly 100 million neurons.
  \item A 1 petaflop supercomputer could simulate a mouse brain.
  \item A human brain has roughly 100 billion neurons.
  \item Computer performance is measured in \ac{FLOPS}.
  \item Simulating the human brain will require computing power at the exascale ($10^18$ \ac{FLOPS}).
\end{itemize}

\begin{table}[!htbp]
\centering
\caption{Metric prefixes}
\label{tab:metric}
\begin{tabu}{@{}llll@{}}
\toprule
kilo & k & $10^3$    & \num\{1000\}                \\
mega & M & $10^6$    & \num\{1000000\}             \\
giga & G & $10^9$    & \num\{1000000000\}          \\
tera & T & $10^{12}$ & \num\{1000000000000\}       \\
peta & P & $10^{15}$ & \num\{1000000000000000\}    \\
exa  & E & $10^{18}$ & \num\{1000000000000000000\} \\ 
\bottomrule
\end{tabu}
\end{table}

The \ac{HBP} plans to build a supercomputer at the petascale with 50 petabytes of memory, 50 petaflops and less than 4MW power consumption for 2017. Their long-term goal is to reach the required exascale machine with 200 petabyte memory and 1 exaflop performance for 2021 \autocite{Walker2012}.



HERE




\begin{quotation}
  All of our mental states, everything from feeling pains to reflecting on philosophical problems, is caused by lower level neuronal firings in the brain. Variable rates of neuron firing at synapses, as far as we know anything about it, provide the causal explanation for all of our mental life. And the mental processes that are caused by neurobiological processes are themselves realized in the structure of the brain. They are higher level features of the brain in the same sense that the solidity of this paper or the liquidity of water is a higher level feature of the system of molecules of which the table or the water is composed.

  To put this in one sentence, the solution to the traditional mind-body problem is this: Mental states are caused by neurobiological processes and are themselves realized in the system composed of the neurobiological elements.\sourceatright{\autocite{Searle1998}}
\end{quotation}


Why Minds Are Not Like Computers \autocite{Schulman2009}
Software – Hardware == Mind – Brain ??? analogy

"The power of the computer derives not from its ability to perform complex operations, but from its ability to perform many simple operations very quickly."

Layers of abstraction in computers:\\
1.	user interface\\
2.	high level programming language\\
3.	machine language\\
4.	proessor microarchitecture\\
5.	Boolean logic gates\\
6.	transistors\\

layers of abstraction in brain:\\
1.	personality?\\
2.	Thinking?\\
3.	Chemical /electrical signals/activity?\\
4.	Divided Brain regions/structure\\
5.	Neurons\\
6.	Dendrites (input) and axons (output)?\\


Computers are faster and better than humans in many tasks already.

\begin{quote}
"The weaknesses of the computational approach include its assumption that cognition can be reduced to mathematics and the difficulty of including noncognitive factors in creativity." \autocite[p.457]{Mayer1999}
\end{quote}

\todo{find references}
\todo{neural networks and other models based on the brain}

Perhaps we need to have that complete picture of how the brainw orks in order to understand human creativity. I would argue computer creativity is part of general \ac{AI}, and for general \ac{AI} we need massive amounts of general knoweldge.
\todo{common sense research}
\todo{again talk about how this is relevant for my project}


http://users.ecs.soton.ac.uk/harnad/Papers/Py104/searle.comp.html
Is the Brain a Digital Computer? John R. Searle
(1990) Presidential Address to the American Philosophical Association
\autocite{Searle1990}

``Structure of the child machine = Heredetary material\\
Changes of the child machine = Mutations\\
Natural selection = Judgement of the experimenter''\autocite{Turing2009} 

``Digital computers have often been described as mechanical brains.''\autocite{Turing1951} 


``...the wisest ground on which to criticise the description of digital computers as `mechanical brains' or `electronic brains' is that, although they might be programmed to behave like brains, we do not at present know how this should be done.''\autocite{Turing1951} 






AARON 

\begin{quotation}
  Cohen is the author of AARON, perhaps the longest-lived and certainly the most creative artificial intelligence program in daily use. Cohen viewed AARON as his collaborator. At times during their decades long relationship AARON was quite autonomous, responsible for the composition, coloring and other aspects of a work; more recently, AARON served Cohen by making drawings that Cohen would develop into paintings. Cohen's death is the end of a lengthy partnership between an artist and an artificial intelligence.\sourceatright{\autocite{Cohen2016}}
\end{quotation}

\begin{quotation}
  Cohen had no patience for the ``is it art?'' question. He showed AARON's work in the world's galleries, museums and science centers -- the Tate, the Stedelijk, the San Francisco Museum of Art, Documenta, the Boston Computer Museum, the Ontario Science Center, and many others. His audiences might have been drawn in by curiosity and the novelty of computer-generated art, but they would soon ask, how can a machine make such marvelous pictures? How does it work? The very questions that Cohen asked himself throughout his career.\sourceatright{\autocite{Cohen2016}}
\end{quotation}

\todo{aaron stuff}
\url{http://collections.vam.ac.uk/name/cohen-harold/6433/}

\begin{quotation}
  \ldots we'll be seeing an increasing number of artists turning to robotic art of one sort or another in the next five or ten years. We're already seeing some. It's also a pretty safe bet that for the most part they'll be using off-the-shelf robots; that the ``art'' will be manifested in dreaming up contexts they were never intended for; and the culture's definitions of art will change accordingly.
  \sourceatright{\autocite{Cohen2007}}
\end{quotation}

\begin{quotation}
  Shouldn't it be possible, I wondered, to write the rules for generating material for a painting and then simply follow the rules?  In this way, it would be almost as if the painting was painting itself; and I would be relieved of the uncertain task of inventing on a day-to-day basis. 

  That was a little naïve, of course; it simply shifted the burden of invention to another place, another level. I'm still inventing on a day to day basis, but now it's likely to be algorithms for doing particular tasks that I'm inventing.
  \sourceatright{\autocite{Cohen2007}}
\end{quotation}

\begin{quotation}
  I'd like to end with a couple of observations about AARON's algorithm. Firstly; I think it's fair to say that nothing of what has happened could have happened unless I had drawn upon a lifetime of experience as a colorist.  I've evidently managed to pack all that experience into a few lines of code,  yet nothing in the code looks remotely like what I would have been doing as a painter, and AARON's algorithm isn't something a human artist could apply by hand, so to speak.
  \sourceatright{\autocite{Cohen2007}}
\end{quotation}

\begin{quotation}
  It's twenty years since I first realized that I could never turn AARON into a colorist by having it emulate my own expertise; in that case simply because it lacked the hardware upon which that expertise depended. Now I have AARON exercising an algorithm that couldn't be emulated by human colorists, presumably because they lack the hardware to do what AARON does. (and by hardware, in this case I mean the intellectual machinery that can build a stable enough representation and juggle enough variables, as AARON does in running the algorithm.) 
  \sourceatright{\autocite{Cohen2007}}
\end{quotation}

\begin{quotation}
  None of this would be interesting if AARON were an indifferent colorist. But I think I can claim, without undue immodesty, that AARON is a world-class colorist, significantly more inventive and infinitely more productive than I ever was myself. And I conclude that, after decades of expert systems  built to simulate human expertise, AARON has emerged as an expert in its own right. That marks a significant change of state, a change of level, in the never-ending pursuit of autonomy, not merely an incremental change in what the program is able to do. 
  \sourceatright{\autocite{Cohen2007}}
\end{quotation}

\begin{quotation}
  If I were writing AARON's biography today, I might almost say that AARON was a twinkle in its parent's eye in 1963; it was conceived in 1972 but not born until 2006. It has been a long gestation, and right now the parent is struggling to direct an unruly child, keeping it fed and changing its diapers. He has no idea when the child will be potty-trained, much less how long it will be before it reaches adulthood.
  \sourceatright{\autocite{Cohen2007}}
\end{quotation}


% MOVE TO ANALYSIS
\begin{quotation}
  [The use of computers] became an instrument, not of combinatorial accumulation, but of anti-combinatorial reduction. It served not to create combinations but to eliminate them.\sourceatright{\autocite[p.131]{Mathews2005}}
\end{quotation}


\spirals


Where does this project stand in the wider world and the progress of computing, \ac{AI} and creativity? \ac{AI} and robotics is alluring as a research topic because it is so prevelant in Science Fiction. Computer creativity rarely plays a central role though. We can regularly read headlines that tell us that yet another kind of \ac{AI}-bot has won some game against a human player. Or we see videos of some innovative ground-breaking kind of new robot which claims to be near human-like (and yet cannot walk up stairs easily or hold a decent conversation). There are many examples of advances that are hailed as the next big thing which aren't all that great in the grand scheme of things. 

\subsection{AI}
% This is also evident in games, for example \ac{VR} and \ac{AR}. The Oculus Rift and similar systems are advertised so much you might believe they are actually about to hit mainstream and every kid will own a \ac{VR} console and headset. Yet they are still way too expensive to be mainstream and motion sickness is also still an issue (and probably always will). These industries are so ``hip'' any publication is seen as the new cool thing without taking into account the history and work that has been done previously in perhaps slightly different disciplines. This is the case for example with a recent article on \ac{VR} sickness and how to compat it. This is a well known problem already---motion sickness already exists in normal games. Similar to epilepsy problems.

% \todo{find links for motion sickness}
% \todo{find links for epilepsy}
% \todo{find links for oculus rift and pokenmon go etc}

% \ac{AR} has very recently received a massive boom thanks to Pokenmon Go (released in Australia, New Zealand and the USA in July 2016). It has become a phenomenon since then.
% \todo{find pokemon links}

What about IBM's Watson\footnote{See \url{http://www.ibm.com/watson/}}, Microsoft's Twitter \ac{AI} chatbot Tay\footnote{See \url{https://web.archive.org/web/20160414074049/https://www.tay.ai/} for an archived version of the original website which is now offline. See also \url{https://twitter.com/tayandyou}, \url{https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter}, and \url{https://www.theguardian.com/technology/2016/mar/30/microsoft-racist-sexist-chatbot-twitter-drugs}. Wikipedia also has a good article and sources on Tay: \url{https://en.wikipedia.org/wiki/Tay_(bot)}}, Google's AlphaGo\footnote{See \url{https://deepmind.com/alpha-go}} and Hanson Robotics Sophia robot\footnote{See \url{http://www.hansonrobotics.com/}}? How does this relate to my work? Practially of course they are all unrelated. On a deeper level though we can start asking interesting questions. 

\url{https://www.engadget.com/2016/08/07/ibms-watson-ai-saved-a-woman-from-leukemia/}
\url{https://xkcd.com/1619/} XKCD WATSON
\url{http://www.wsj.com/articles/SB10001424052748703407304576154313126987674}

\begin{description}
  \item[IBM Watson] Watson is a question answering expert system. It famously won against human Jeopardy! champions in 2011.
  \item[Microsoft Tay] 
  \item[Google AlphaGo] AlphaGo is a system for playing the game Go. It won against a top human professional player in 2015.
  \item[Hansen Sophia]
\end{description}

I think these are interesting examples to study since they are supposedly on the forefront of \ac{AI} development. Life-like robots like Sophia still live in the `uncanny valley'. Her voice is creepy and unhuman, her intelligence or her capabilities if understanding conversations are clearly flawed (as shown by her viral remark about supporting genocide).\todo{check} Watson is clever and fast in finding answers for specific questions but he still had problems with humour (e.g. BLAHBLA\todo{find example}) but information lookup is arguably fairly easy and straightforward process within \ac{IR}---sure, it requires processing power and memory storage or access but it is based on simple matching of keywords, not any fancy heuristic algorithms. Microsofts twitter chatbot went viral and users `taught' it nasty swearwords \todo{check} quickly and Microsoft had to take the bot down. It has since apologised although any official documentation on it has disappeared \todo{check}. Google's AlphaGo has been hailed as a breakthrough in \ac{AI} but similar to Watson it is a very targeted and limited program. 

To me it seems the real breakthrough happens when (and if) the first robots appears which isn't as big as a house, can play Go, Chess and hide-and-seek, geniunely manages to get around he uncanny valley effect, has vast knowledge in his memory for instant information lookup, can hold a normal conversation without causing a war, etc, etc---you get the picture. General \ac{AI} is where it's at. Humans can do all the things we do. Children aren't born with only a single function. Imagine a world where humans only have one specialism and can;t do anything else. Mary is a Chess player but can't move her arms. Bob is a medical diagnosis expert but he can't hold a conversation. Movement, speech, memory---they are all vastly complex systems. And I haven't even touched creativity yet.

\todo{whats the point im making? how does this relate to my work?}
Perhpas this `uncanny valley' exists in creativity too. If a robot who looks vaguely human but not quite well enough, or he/she/it sounds almost human but not quite---perhaps if a robot can crack a joke like a human but not quite---perhaps this could be considered uncanny valley too? The philosphical zombies I mentioend in chapter~\ref{ch:interpretation}\marginnote{§~\ref{ch:interpretation}} live in this uncanny valley?

\todo{p and H creativity for computers?}




\paragraph{Expert Systems vs General AI}
Is computer creativity an expert system or does it fall into general \ac{AI}? 

\paragraph{Machines self-assessing}
Perhaps there is an argument that if humans are the only entities who can judge whether another human is being creative, then machines should be assessing themselves. This is a paradoxical concepts though. Since machines are products made my humans, they can never be autonomous in that sense. If machines had evolved like other animals besides us this argument might hold but obviously that is not the case.


\section{Ethical Computers}

This is currently a big issue for example in self-driving vehicles.
and has always been a faviroite subject in Science Fiction.


\end{document}
